2025-02-28:16:25:57,007 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:16:25:57,009 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:16:25:57,064 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:16:25:57,069 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:16:25:57,072 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:16:26:07,893 INFO     [lm_eval.__main__:379] Selected Tasks: ['math-500']
2025-02-28:16:26:07,895 INFO     [lm_eval.evaluator:169] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-02-28:16:26:07,895 INFO     [lm_eval.evaluator:206] Initializing openai-chat-completions model, with arguments: {'model': 'deepseek-reasoner', 'timeout': 30, 'max_retries': 10}
2025-02-28:16:26:07,895 WARNING  [lm_eval.models.openai_completions:117] chat-completions endpoint requires the `--apply_chat_template` flag.
2025-02-28:16:26:07,895 WARNING  [lm_eval.models.api_models:109] Batch size > 1 detected. Ensure your API supports batched requests with varying total sequence lengths.
2025-02-28:16:26:07,895 INFO     [lm_eval.models.api_models:117] Using max length 2048 - 1
2025-02-28:16:26:07,895 INFO     [lm_eval.models.api_models:120] Concurrent requests are disabled. To enable concurrent requests, set `num_concurrent` > 1.
2025-02-28:16:26:07,895 INFO     [lm_eval.models.api_models:135] Using tokenizer None
2025-02-28:16:26:07,989 WARNING  [lm_eval.models.openai_completions:127] Chat completions does not support batching. Defaulting to batch size 1.
2025-02-28:16:26:07,989 INFO     [lm_eval.evaluator:226] Using cache at ./cache/cache.db_rank0.db
2025-02-28:16:26:14,013 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-02-28:16:26:14,013 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-02-28:16:26:14,096 INFO     [lm_eval.evaluator:271] num_fewshot has been set to 0 for math-500 in its config. Manual configuration will be ignored.
2025-02-28:16:26:14,096 WARNING  [lm_eval.evaluator:421] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-02-28:16:26:14,096 INFO     [lm_eval.api.task:420] Building contexts for math-500 on rank 0...
100%|█████████████████████████████████████████████████████████████████████████████| 500/500 [00:00<00:00, 805.90it/s]
2025-02-28:16:26:14,988 INFO     [lm_eval.evaluator:517] Running generate_until requests
2025-02-28:16:26:14,988 INFO     [lm_eval.api.model:261] Loading 'generate_until' responses from cache './cache/cache.db_rank0.db' where possible...
Checking cached requests: 100%|██████████████████████████████████████████████████| 500/500 [00:00<00:00, 1709.84it/s]
2025-02-28:16:26:15,281 INFO     [lm_eval.api.model:285] Cached requests: 0, Requests remaining: 500
Requesting API:   0%|                                                                        | 0/500 [00:00<?, ?it/s]2025-02-28:16:26:15,286 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:16:26:15,287 WARNING  [lm_eval.models.api_models:293] Cannot determine EOS string to pass to stop sequence. Manually set by passing `eos_string` to model_args.
2025-02-28:16:26:16,264 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:   0%|                                                             | 1/500 [01:21<11:18:16, 81.56s/it]2025-02-28:16:27:36,842 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:16:27:37,674 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
^C
2025-02-28:16:29:00,196 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:16:29:00,199 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:16:29:00,202 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:16:29:00,206 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:16:29:00,265 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:16:29:11,275 WARNING  [lm_eval.__main__:316]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-02-28:16:29:11,279 INFO     [lm_eval.__main__:379] Selected Tasks: ['math-500']
2025-02-28:16:29:11,281 INFO     [lm_eval.evaluator:169] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-02-28:16:29:11,281 INFO     [lm_eval.evaluator:206] Initializing openai-chat-completions model, with arguments: {'model': 'deepseek-reasoner', 'timeout': 30, 'max_retries': 10}
2025-02-28:16:29:11,281 WARNING  [lm_eval.models.openai_completions:117] chat-completions endpoint requires the `--apply_chat_template` flag.
2025-02-28:16:29:11,281 INFO     [lm_eval.models.api_models:117] Using max length 2048 - 1
2025-02-28:16:29:11,281 INFO     [lm_eval.models.api_models:120] Concurrent requests are disabled. To enable concurrent requests, set `num_concurrent` > 1.
2025-02-28:16:29:11,281 INFO     [lm_eval.models.api_models:135] Using tokenizer None
2025-02-28:16:29:11,377 INFO     [lm_eval.evaluator:226] Using cache at ./cache/cache.db_rank0.db
2025-02-28:16:29:18,507 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-02-28:16:29:18,508 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-02-28:16:29:18,595 INFO     [lm_eval.evaluator:271] num_fewshot has been set to 0 for math-500 in its config. Manual configuration will be ignored.
2025-02-28:16:29:18,595 WARNING  [lm_eval.evaluator:421] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-02-28:16:29:18,601 INFO     [lm_eval.evaluator:517] Running generate_until requests
2025-02-28:16:29:18,602 INFO     [lm_eval.api.model:261] Loading 'generate_until' responses from cache './cache/cache.db_rank0.db' where possible...
Checking cached requests: 100%|██████████████████████████████████████████████████████| 5/5 [00:00<00:00, 3201.27it/s]
2025-02-28:16:29:18,604 INFO     [lm_eval.api.model:285] Cached requests: 1, Requests remaining: 4
Requesting API:   0%|                                                                          | 0/4 [00:00<?, ?it/s]2025-02-28:16:29:18,606 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:16:29:18,606 WARNING  [lm_eval.models.api_models:293] Cannot determine EOS string to pass to stop sequence. Manually set by passing `eos_string` to model_args.
2025-02-28:16:29:19,600 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  25%|████████████████▎                                                | 1/4 [04:21<13:05, 261.98s/it]2025-02-28:16:33:40,583 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:16:33:41,425 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  50%|████████████████████████████████▌                                | 2/4 [05:49<05:19, 159.64s/it]2025-02-28:16:35:08,589 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:16:35:09,387 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  75%|████████████████████████████████████████████████▊                | 3/4 [07:09<02:02, 122.91s/it]2025-02-28:16:36:27,789 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:16:36:28,586 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:16:37:30,407 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:16:38:32,232 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:16:39:35,052 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:16:40:39,922 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API: 100%|█████████████████████████████████████████████████████████████████| 4/4 [13:30<00:00, 202.56s/it]
2025-02-28:16:42:59,992 INFO     [lm_eval.loggers.evaluation_tracker:209] Saving results aggregated
2025-02-28:16:42:59,993 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: math-500
2025-02-28:17:39:44,804 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:17:39:44,806 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:17:39:44,808 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:17:39:44,810 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:17:39:44,867 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:17:39:55,890 WARNING  [lm_eval.__main__:316]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-02-28:17:39:55,892 INFO     [lm_eval.__main__:379] Selected Tasks: ['math-500']
2025-02-28:17:39:55,894 INFO     [lm_eval.evaluator:169] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-02-28:17:39:55,894 INFO     [lm_eval.evaluator:206] Initializing openai-chat-completions model, with arguments: {'model': 'deepseek-reasoner', 'timeout': 30, 'max_retries': 10}
2025-02-28:17:39:55,894 WARNING  [lm_eval.models.openai_completions:117] chat-completions endpoint requires the `--apply_chat_template` flag.
2025-02-28:17:39:55,895 INFO     [lm_eval.models.api_models:117] Using max length 2048 - 1
2025-02-28:17:39:55,895 INFO     [lm_eval.models.api_models:120] Concurrent requests are disabled. To enable concurrent requests, set `num_concurrent` > 1.
2025-02-28:17:39:55,895 INFO     [lm_eval.models.api_models:135] Using tokenizer None
2025-02-28:17:39:55,992 INFO     [lm_eval.evaluator:226] Using cache at ./cache/cache.db_rank0.db
2025-02-28:17:40:00,491 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-02-28:17:40:00,491 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-02-28:17:40:00,585 INFO     [lm_eval.evaluator:271] num_fewshot has been set to 0 for math-500 in its config. Manual configuration will be ignored.
2025-02-28:17:40:00,586 WARNING  [lm_eval.evaluator:421] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-02-28:17:40:00,592 INFO     [lm_eval.evaluator:517] Running generate_until requests
2025-02-28:17:40:00,593 INFO     [lm_eval.api.model:261] Loading 'generate_until' responses from cache './cache/cache.db_rank0.db' where possible...
Checking cached requests: 100%|████████████████████████████████████████████████████| 20/20 [00:00<00:00, 4029.11it/s]
2025-02-28:17:40:00,599 INFO     [lm_eval.api.model:285] Cached requests: 5, Requests remaining: 15
Requesting API:   0%|                                                                         | 0/15 [00:00<?, ?it/s]2025-02-28:17:40:00,601 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:17:40:00,602 WARNING  [lm_eval.models.api_models:293] Cannot determine EOS string to pass to stop sequence. Manually set by passing `eos_string` to model_args.
2025-02-28:17:40:01,566 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:   7%|████▎                                                            | 1/15 [00:58<13:32, 58.02s/it]2025-02-28:17:40:58,617 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:17:40:59,434 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  13%|████████▋                                                        | 2/15 [02:26<16:26, 75.88s/it]2025-02-28:17:42:26,994 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:17:42:27,902 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  20%|█████████████                                                    | 3/15 [04:22<18:52, 94.39s/it]2025-02-28:17:44:23,417 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:17:44:24,236 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  27%|█████████████████▎                                               | 4/15 [05:21<14:42, 80.26s/it]2025-02-28:17:45:22,024 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:17:45:22,835 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:17:46:24,678 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  33%|█████████████████████▎                                          | 5/15 [16:14<47:46, 286.66s/it]2025-02-28:17:56:14,637 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:17:56:15,447 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  40%|█████████████████████████▌                                      | 6/15 [19:19<37:50, 252.30s/it]2025-02-28:17:59:20,246 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:17:59:21,059 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  47%|█████████████████████████████▊                                  | 7/15 [22:56<32:06, 240.77s/it]2025-02-28:18:02:57,271 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:02:58,078 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  53%|██████████████████████████████████▏                             | 8/15 [25:25<24:39, 211.35s/it]2025-02-28:18:05:25,618 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:05:26,654 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:18:06:28,476 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  60%|██████████████████████████████████████▍                         | 9/15 [27:22<18:11, 181.90s/it]2025-02-28:18:07:22,761 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:07:23,600 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:18:08:25,432 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:18:09:27,292 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  67%|██████████████████████████████████████████                     | 10/15 [31:15<16:28, 197.73s/it]2025-02-28:18:11:15,931 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:11:16,795 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  73%|██████████████████████████████████████████████▏                | 11/15 [33:09<11:28, 172.13s/it]2025-02-28:18:13:10,037 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:13:10,867 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  80%|██████████████████████████████████████████████████▍            | 12/15 [35:21<08:00, 160.05s/it]2025-02-28:18:15:22,464 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:15:23,364 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  87%|██████████████████████████████████████████████████████▌        | 13/15 [38:21<05:31, 165.90s/it]2025-02-28:18:18:21,811 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:18:22,629 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  93%|██████████████████████████████████████████████████████████▊    | 14/15 [44:57<03:55, 235.43s/it]2025-02-28:18:24:57,899 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:24:58,688 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API: 100%|███████████████████████████████████████████████████████████████| 15/15 [47:11<00:00, 188.75s/it]
2025-02-28:18:27:22,989 INFO     [lm_eval.loggers.evaluation_tracker:209] Saving results aggregated
2025-02-28:18:27:22,990 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: math-500
2025-02-28:18:40:14,190 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:18:40:14,192 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:18:40:14,194 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:18:40:14,196 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:18:40:14,198 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:18:40:24,477 WARNING  [lm_eval.__main__:316]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-02-28:18:40:24,480 INFO     [lm_eval.__main__:379] Selected Tasks: ['math-500']
2025-02-28:18:40:24,482 INFO     [lm_eval.evaluator:169] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-02-28:18:40:24,482 INFO     [lm_eval.evaluator:206] Initializing openai-chat-completions model, with arguments: {'model': 'deepseek-reasoner', 'timeout': 30, 'max_retries': 10}
2025-02-28:18:40:24,482 WARNING  [lm_eval.models.openai_completions:117] chat-completions endpoint requires the `--apply_chat_template` flag.
2025-02-28:18:40:24,482 INFO     [lm_eval.models.api_models:117] Using max length 2048 - 1
2025-02-28:18:40:24,482 INFO     [lm_eval.models.api_models:120] Concurrent requests are disabled. To enable concurrent requests, set `num_concurrent` > 1.
2025-02-28:18:40:24,482 INFO     [lm_eval.models.api_models:135] Using tokenizer None
2025-02-28:18:40:24,565 INFO     [lm_eval.evaluator:226] Using cache at ./cache/cache.db_rank0.db
2025-02-28:18:40:29,042 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-02-28:18:40:29,042 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-02-28:18:40:29,080 INFO     [lm_eval.evaluator:271] num_fewshot has been set to 0 for math-500 in its config. Manual configuration will be ignored.
2025-02-28:18:40:29,081 WARNING  [lm_eval.evaluator:421] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-02-28:18:40:29,086 INFO     [lm_eval.evaluator:517] Running generate_until requests
2025-02-28:18:40:29,086 INFO     [lm_eval.api.model:261] Loading 'generate_until' responses from cache './cache/cache.db_rank0.db' where possible...
Checking cached requests: 100%|████████████████████████████████████████████████████| 50/50 [00:00<00:00, 4433.35it/s]
2025-02-28:18:40:29,098 INFO     [lm_eval.api.model:285] Cached requests: 20, Requests remaining: 30
Requesting API:   0%|                                                                         | 0/30 [00:00<?, ?it/s]2025-02-28:18:40:29,099 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:40:29,100 WARNING  [lm_eval.models.api_models:293] Cannot determine EOS string to pass to stop sequence. Manually set by passing `eos_string` to model_args.
2025-02-28:18:40:30,123 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:   3%|██▏                                                              | 1/30 [01:35<46:15, 95.70s/it]2025-02-28:18:42:04,803 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:42:05,589 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:   7%|████▏                                                         | 2/30 [05:57<1:30:18, 193.51s/it]2025-02-28:18:46:26,775 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:46:27,600 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  10%|██████▏                                                       | 3/30 [07:34<1:07:07, 149.17s/it]2025-02-28:18:48:03,171 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:48:04,095 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  13%|████████▌                                                       | 4/30 [09:03<54:29, 125.75s/it]2025-02-28:18:49:33,038 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:49:33,875 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  17%|██████████▋                                                     | 5/30 [11:07<52:00, 124.83s/it]2025-02-28:18:51:36,221 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:51:37,031 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  20%|████████████▍                                                 | 6/30 [14:44<1:02:29, 156.25s/it]2025-02-28:18:55:13,462 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:18:55:14,284 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  23%|██████████████▍                                               | 7/30 [21:53<1:34:05, 245.46s/it]2025-02-28:19:02:22,604 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:02:23,430 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  27%|████████████████▌                                             | 8/30 [23:07<1:09:59, 190.87s/it]2025-02-28:19:03:36,592 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:03:37,412 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  30%|██████████████████▌                                           | 9/30 [25:18<1:00:17, 172.27s/it]2025-02-28:19:05:47,955 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:05:48,790 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  33%|█████████████████████                                          | 10/30 [26:28<46:48, 140.44s/it]2025-02-28:19:06:57,132 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:06:57,966 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  37%|███████████████████████                                        | 11/30 [28:32<42:56, 135.60s/it]2025-02-28:19:09:01,738 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:09:02,579 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  40%|█████████████████████████▏                                     | 12/30 [29:42<34:40, 115.59s/it]2025-02-28:19:10:11,555 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:10:12,427 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  43%|███████████████████████████▎                                   | 13/30 [36:16<56:39, 199.99s/it]2025-02-28:19:16:45,764 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:16:46,597 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:19:17:48,395 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  47%|█████████████████████████████▍                                 | 14/30 [39:36<53:21, 200.08s/it]2025-02-28:19:20:06,061 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:20:06,879 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  50%|███████████████████████████████▌                               | 15/30 [41:26<43:12, 172.85s/it]2025-02-28:19:21:55,787 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:21:56,601 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  53%|█████████████████████████████████▌                             | 16/30 [43:53<38:31, 165.11s/it]2025-02-28:19:24:22,933 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:24:23,770 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:19:25:25,611 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  57%|███████████████████████████████████▋                           | 17/30 [47:31<39:10, 180.84s/it]2025-02-28:19:28:00,338 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:28:01,175 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  60%|█████████████████████████████████████▊                         | 18/30 [48:42<29:35, 147.97s/it]2025-02-28:19:29:11,800 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:29:12,613 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  63%|███████████████████████████████████████▉                       | 19/30 [49:54<22:55, 125.02s/it]2025-02-28:19:30:23,342 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:30:24,154 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:19:31:25,998 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:19:32:27,840 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  67%|██████████████████████████████████████████                     | 20/30 [53:20<24:54, 149.44s/it]2025-02-28:19:33:49,706 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:33:50,523 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  70%|████████████████████████████████████████████                   | 21/30 [54:11<17:59, 119.89s/it]2025-02-28:19:34:40,708 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:34:41,529 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  73%|██████████████████████████████████████████████▏                | 22/30 [57:37<19:24, 145.56s/it]2025-02-28:19:38:06,124 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:38:06,948 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  77%|████████████████████████████████████████████████▎              | 23/30 [58:48<14:22, 123.28s/it]2025-02-28:19:39:17,452 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:39:18,263 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  80%|████████████████████████████████████████████████▊            | 24/30 [1:14:16<36:29, 364.88s/it]2025-02-28:19:54:45,893 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:54:46,708 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  83%|██████████████████████████████████████████████████▊          | 25/30 [1:15:31<23:09, 277.95s/it]2025-02-28:19:56:01,055 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:56:01,992 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  87%|████████████████████████████████████████████████████▊        | 26/30 [1:16:41<14:21, 215.45s/it]2025-02-28:19:57:10,677 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:19:57:11,496 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  90%|██████████████████████████████████████████████████████▉      | 27/30 [1:20:25<10:53, 217.93s/it]2025-02-28:20:00:54,403 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:00:55,282 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  93%|████████████████████████████████████████████████████████▉    | 28/30 [1:21:49<05:55, 177.82s/it]2025-02-28:20:02:18,626 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:02:19,454 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API:  97%|██████████████████████████████████████████████████████████▉  | 29/30 [1:22:43<02:20, 140.52s/it]2025-02-28:20:03:12,137 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:03:12,961 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
Requesting API: 100%|█████████████████████████████████████████████████████████████| 30/30 [1:23:40<00:00, 167.35s/it]
2025-02-28:20:04:20,791 INFO     [lm_eval.loggers.evaluation_tracker:209] Saving results aggregated
2025-02-28:20:04:20,793 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: math-500
2025-02-28:20:08:30,291 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:20:08:30,293 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:20:08:30,295 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:20:08:30,297 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:20:08:30,299 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:20:08:41,072 WARNING  [lm_eval.__main__:316]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-02-28:20:08:41,075 INFO     [lm_eval.__main__:379] Selected Tasks: ['math-500']
2025-02-28:20:08:41,077 INFO     [lm_eval.evaluator:169] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-02-28:20:08:41,077 INFO     [lm_eval.evaluator:206] Initializing openai-chat-completions model, with arguments: {'model': 'deepseek-reasoner', 'timeout': 30, 'max_retries': 10}
2025-02-28:20:08:41,077 WARNING  [lm_eval.models.openai_completions:117] chat-completions endpoint requires the `--apply_chat_template` flag.
2025-02-28:20:08:41,077 INFO     [lm_eval.models.api_models:117] Using max length 2048 - 1
2025-02-28:20:08:41,077 INFO     [lm_eval.models.api_models:120] Concurrent requests are disabled. To enable concurrent requests, set `num_concurrent` > 1.
2025-02-28:20:08:41,077 INFO     [lm_eval.models.api_models:135] Using tokenizer None
2025-02-28:20:08:41,174 INFO     [lm_eval.evaluator:226] Using cache at ./cache/cache.db_rank0.db
2025-02-28:20:08:46,446 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-02-28:20:08:46,446 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-02-28:20:08:46,483 INFO     [lm_eval.evaluator:271] num_fewshot has been set to 0 for math-500 in its config. Manual configuration will be ignored.
2025-02-28:20:08:46,483 WARNING  [lm_eval.evaluator:421] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-02-28:20:08:46,488 INFO     [lm_eval.evaluator:517] Running generate_until requests
2025-02-28:20:08:46,488 INFO     [lm_eval.api.model:261] Loading 'generate_until' responses from cache './cache/cache.db_rank0.db' where possible...

Checking cached requests:   0%|          | 0/100 [00:00<?, ?it/s]
Checking cached requests: 100%|██████████| 100/100 [00:00<00:00, 1283.23it/s]
2025-02-28:20:08:46,567 INFO     [lm_eval.api.model:285] Cached requests: 50, Requests remaining: 50

Requesting API:   0%|          | 0/50 [00:00<?, ?it/s]2025-02-28:20:08:46,570 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:08:46,571 WARNING  [lm_eval.models.api_models:293] Cannot determine EOS string to pass to stop sequence. Manually set by passing `eos_string` to model_args.
2025-02-28:20:08:47,541 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:09:49,372 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   2%|▏         | 1/50 [02:48<2:17:57, 168.92s/it]2025-02-28:20:11:35,493 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:11:36,284 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:12:38,131 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   4%|▍         | 2/50 [06:04<2:27:40, 184.59s/it]2025-02-28:20:14:51,055 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:14:51,875 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:15:53,671 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   6%|▌         | 3/50 [08:51<2:18:19, 176.58s/it]2025-02-28:20:17:38,103 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:17:38,878 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:18:40,712 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   8%|▊         | 4/50 [11:17<2:06:05, 164.47s/it]2025-02-28:20:20:04,011 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:20:04,810 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  10%|█         | 5/50 [12:31<1:38:51, 131.81s/it]2025-02-28:20:21:17,919 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:21:18,749 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  12%|█▏        | 6/50 [13:44<1:22:06, 111.97s/it]2025-02-28:20:22:31,381 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:22:32,187 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  14%|█▍        | 7/50 [14:38<1:06:39, 93.01s/it] 2025-02-28:20:23:25,341 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:23:26,191 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  16%|█▌        | 8/50 [16:12<1:05:09, 93.08s/it]2025-02-28:20:24:58,588 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:24:59,591 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  18%|█▊        | 9/50 [17:58<1:06:31, 97.35s/it]2025-02-28:20:26:45,331 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:26:46,166 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  20%|██        | 10/50 [18:55<56:32, 84.82s/it] 2025-02-28:20:27:42,101 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:27:42,932 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  22%|██▏       | 11/50 [22:08<1:16:40, 117.97s/it]2025-02-28:20:30:55,210 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:30:56,025 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  24%|██▍       | 12/50 [24:31<1:19:26, 125.44s/it]2025-02-28:20:33:17,748 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:33:18,556 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:34:20,390 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:35:22,209 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:36:25,093 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  26%|██▌       | 13/50 [30:23<1:59:47, 194.24s/it]2025-02-28:20:39:10,309 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:39:11,214 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  28%|██▊       | 14/50 [32:41<1:46:13, 177.04s/it]2025-02-28:20:41:27,600 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:41:28,414 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:42:30,275 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:43:32,074 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  30%|███       | 15/50 [38:16<2:11:06, 224.77s/it]2025-02-28:20:47:02,981 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:47:03,772 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  32%|███▏      | 16/50 [38:59<1:36:19, 169.99s/it]2025-02-28:20:47:45,748 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:47:46,588 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  34%|███▍      | 17/50 [40:40<1:22:10, 149.40s/it]2025-02-28:20:49:27,262 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:49:28,052 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  36%|███▌      | 18/50 [42:03<1:08:59, 129.37s/it]2025-02-28:20:50:50,006 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:50:50,839 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:51:52,725 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  38%|███▊      | 19/50 [45:34<1:19:32, 153.95s/it]2025-02-28:20:54:21,229 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:54:22,086 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:55:23,914 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:56:25,804 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  40%|████      | 20/50 [49:59<1:33:36, 187.21s/it]2025-02-28:20:58:45,945 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:20:58:46,790 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:20:59:48,611 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  42%|████▏     | 21/50 [52:20<1:23:44, 173.25s/it]2025-02-28:21:01:06,636 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:01:07,464 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:02:09,289 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:03:11,128 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:04:14,002 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  44%|████▍     | 22/50 [57:38<1:41:14, 216.94s/it]2025-02-28:21:06:25,476 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:06:26,313 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  46%|████▌     | 23/50 [58:47<1:17:31, 172.28s/it]2025-02-28:21:07:33,591 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:07:34,404 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  48%|████▊     | 24/50 [1:00:33<1:06:05, 152.54s/it]2025-02-28:21:09:20,073 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:09:20,905 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  50%|█████     | 25/50 [1:02:28<58:51, 141.26s/it]  2025-02-28:21:11:15,024 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:11:15,957 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:12:17,782 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  52%|█████▏    | 26/50 [1:05:44<1:03:03, 157.67s/it]2025-02-28:21:14:30,965 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:14:31,809 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  54%|█████▍    | 27/50 [1:09:09<1:05:51, 171.79s/it]2025-02-28:21:17:55,717 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:17:56,540 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:18:58,432 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:20:00,366 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:21:03,206 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  56%|█████▌    | 28/50 [1:13:40<1:13:57, 201.72s/it]2025-02-28:21:22:27,248 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:22:28,055 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  58%|█████▊    | 29/50 [1:15:28<1:00:43, 173.50s/it]2025-02-28:21:24:14,929 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:24:15,834 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  60%|██████    | 30/50 [1:16:56<49:18, 147.91s/it]  2025-02-28:21:25:43,106 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:25:43,952 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:26:45,743 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:27:47,527 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  62%|██████▏   | 31/50 [1:24:50<1:17:46, 245.62s/it]2025-02-28:21:33:36,711 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:33:37,541 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  64%|██████▍   | 32/50 [1:25:55<57:25, 191.41s/it]  2025-02-28:21:34:41,640 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:34:42,444 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:35:44,237 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  66%|██████▌   | 33/50 [1:32:39<1:12:18, 255.19s/it]2025-02-28:21:41:25,646 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:41:27,528 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  68%|██████▊   | 34/50 [1:34:57<58:43, 220.21s/it]  2025-02-28:21:43:44,236 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:43:45,020 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  70%|███████   | 35/50 [1:36:54<47:19, 189.31s/it]2025-02-28:21:45:41,448 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:45:42,296 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:46:44,117 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  72%|███████▏  | 36/50 [1:38:57<39:30, 169.35s/it]2025-02-28:21:47:44,209 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:47:45,133 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:48:46,986 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  74%|███████▍  | 37/50 [1:40:59<33:37, 155.20s/it]2025-02-28:21:49:46,397 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:49:47,198 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:50:49,012 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  76%|███████▌  | 38/50 [1:43:08<29:27, 147.29s/it]2025-02-28:21:51:55,229 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:51:56,054 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:21:52:57,911 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  78%|███████▊  | 39/50 [1:50:35<43:29, 237.21s/it]2025-02-28:21:59:22,273 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:21:59:23,087 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:00:24,923 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:01:26,713 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  80%|████████  | 40/50 [1:54:32<39:29, 236.95s/it]2025-02-28:22:03:18,590 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:22:03:19,426 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  82%|████████▏ | 41/50 [1:55:54<28:34, 190.51s/it]2025-02-28:22:04:40,753 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:22:04:41,569 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  84%|████████▍ | 42/50 [1:57:35<21:50, 163.76s/it]2025-02-28:22:06:22,093 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:22:06:22,908 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:07:24,763 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:08:26,605 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:09:29,456 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:10:34,298 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  86%|████████▌ | 43/50 [2:05:57<30:56, 265.24s/it]2025-02-28:22:14:44,114 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:22:14:44,953 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:15:46,912 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  88%|████████▊ | 44/50 [2:08:40<23:26, 234.48s/it]2025-02-28:22:17:26,840 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:22:17:27,672 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:18:29,502 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  90%|█████████ | 45/50 [2:14:53<23:00, 276.03s/it]2025-02-28:22:23:39,823 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:22:23:40,691 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  92%|█████████▏| 46/50 [2:16:49<15:12, 228.23s/it]2025-02-28:22:25:36,497 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:22:25:37,316 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  94%|█████████▍| 47/50 [2:22:34<13:09, 263.07s/it]2025-02-28:22:31:20,880 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:22:31:21,666 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:32:23,502 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:33:25,324 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:34:28,214 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:35:33,064 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  96%|█████████▌| 48/50 [2:27:45<09:15, 277.65s/it]2025-02-28:22:36:32,527 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:22:36:33,359 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  98%|█████████▊| 49/50 [2:28:54<03:34, 214.93s/it]2025-02-28:22:37:41,135 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:22:37:41,955 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:38:43,793 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API: 100%|██████████| 50/50 [2:32:20<00:00, 212.15s/it]
Requesting API: 100%|██████████| 50/50 [2:32:20<00:00, 182.80s/it]
2025-02-28:22:41:17,189 INFO     [lm_eval.loggers.evaluation_tracker:209] Saving results aggregated
2025-02-28:22:41:17,192 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: math-500
2025-02-28:22:45:12,083 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:22:45:12,085 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:22:45:12,087 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:22:45:12,089 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:22:45:12,091 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-02-28:22:45:23,567 WARNING  [lm_eval.__main__:316]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-02-28:22:45:23,570 INFO     [lm_eval.__main__:379] Selected Tasks: ['math-500']
2025-02-28:22:45:23,574 INFO     [lm_eval.evaluator:169] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-02-28:22:45:23,574 INFO     [lm_eval.evaluator:206] Initializing openai-chat-completions model, with arguments: {'model': 'deepseek-reasoner', 'timeout': 30, 'max_retries': 10}
2025-02-28:22:45:23,574 WARNING  [lm_eval.models.openai_completions:117] chat-completions endpoint requires the `--apply_chat_template` flag.
2025-02-28:22:45:23,574 INFO     [lm_eval.models.api_models:117] Using max length 2048 - 1
2025-02-28:22:45:23,574 INFO     [lm_eval.models.api_models:120] Concurrent requests are disabled. To enable concurrent requests, set `num_concurrent` > 1.
2025-02-28:22:45:23,575 INFO     [lm_eval.models.api_models:135] Using tokenizer None
2025-02-28:22:45:23,665 INFO     [lm_eval.evaluator:226] Using cache at ./cache/cache.db_rank0.db
2025-02-28:22:45:30,157 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-02-28:22:45:30,157 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-02-28:22:45:30,190 INFO     [lm_eval.evaluator:271] num_fewshot has been set to 0 for math-500 in its config. Manual configuration will be ignored.
2025-02-28:22:45:30,190 WARNING  [lm_eval.evaluator:421] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-02-28:22:45:30,194 INFO     [lm_eval.evaluator:517] Running generate_until requests
2025-02-28:22:45:30,195 INFO     [lm_eval.api.model:261] Loading 'generate_until' responses from cache './cache/cache.db_rank0.db' where possible...

Checking cached requests:   0%|          | 0/500 [00:00<?, ?it/s]
Checking cached requests:  32%|███▏      | 158/500 [00:00<00:00, 1579.14it/s]
Checking cached requests:  80%|████████  | 402/500 [00:00<00:00, 2083.44it/s]
Checking cached requests: 100%|██████████| 500/500 [00:00<00:00, 1773.81it/s]
2025-02-28:22:45:30,477 INFO     [lm_eval.api.model:285] Cached requests: 100, Requests remaining: 400

Requesting API:   0%|          | 0/400 [00:00<?, ?it/s]2025-02-28:22:45:30,480 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:22:45:30,481 WARNING  [lm_eval.models.api_models:293] Cannot determine EOS string to pass to stop sequence. Manually set by passing `eos_string` to model_args.
2025-02-28:22:45:31,451 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   0%|          | 1/400 [05:49<38:44:09, 349.50s/it]2025-02-28:22:51:19,979 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:22:51:20,890 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:52:22,852 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:53:24,736 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:54:27,594 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:55:32,428 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:22:56:41,435 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   0%|          | 2/400 [16:56<59:18:39, 536.48s/it]2025-02-28:23:02:27,348 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:02:28,177 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:23:03:30,033 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   1%|          | 3/400 [19:34<40:06:17, 363.67s/it]2025-02-28:23:05:05,376 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:05:06,345 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   1%|          | 4/400 [26:51<43:10:05, 392.44s/it]2025-02-28:23:12:21,911 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:12:22,720 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:23:13:24,543 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:23:14:26,369 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:23:15:29,198 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   1%|▏         | 5/400 [33:57<44:24:28, 404.73s/it]2025-02-28:23:19:28,436 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:19:29,246 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:23:20:31,102 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   2%|▏         | 6/400 [36:11<34:12:13, 312.52s/it]2025-02-28:23:21:41,966 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:21:42,832 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:23:22:44,658 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:23:23:46,469 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   2%|▏         | 7/400 [40:04<31:16:56, 286.55s/it]2025-02-28:23:25:35,060 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:25:35,898 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   2%|▏         | 8/400 [41:41<24:36:52, 226.05s/it]2025-02-28:23:27:11,567 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:27:12,393 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:23:28:14,206 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   2%|▏         | 9/400 [45:55<25:31:36, 235.03s/it]2025-02-28:23:31:26,338 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:31:27,165 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   2%|▎         | 10/400 [47:58<21:42:39, 200.41s/it]2025-02-28:23:33:29,227 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:33:30,041 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   3%|▎         | 11/400 [1:00:00<38:54:07, 360.02s/it]2025-02-28:23:45:31,150 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:45:32,034 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   3%|▎         | 12/400 [1:01:15<29:27:01, 273.25s/it]2025-02-28:23:46:45,947 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:46:46,774 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   3%|▎         | 13/400 [1:02:44<23:23:26, 217.59s/it]2025-02-28:23:48:15,446 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:48:16,277 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   4%|▎         | 14/400 [1:04:14<19:11:23, 178.97s/it]2025-02-28:23:49:45,196 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:49:46,024 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   4%|▍         | 15/400 [1:05:34<15:57:12, 149.18s/it]2025-02-28:23:51:05,313 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:51:06,236 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:23:52:08,095 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   4%|▍         | 16/400 [1:08:12<16:11:00, 151.72s/it]2025-02-28:23:53:42,942 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:53:43,748 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   4%|▍         | 17/400 [1:09:35<13:57:15, 131.16s/it]2025-02-28:23:55:06,295 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:55:07,113 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   4%|▍         | 18/400 [1:10:32<11:32:03, 108.70s/it]2025-02-28:23:56:02,702 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-02-28:23:56:03,513 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:23:57:05,399 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-02-28:23:58:07,323 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   5%|▍         | 19/400 [1:15:11<16:55:15, 159.88s/it]2025-03-01:00:00:41,817 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:00:42,675 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   5%|▌         | 20/400 [1:21:57<24:41:09, 233.87s/it]2025-03-01:00:07:28,119 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:07:28,935 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   5%|▌         | 21/400 [1:25:11<23:22:12, 221.99s/it]2025-03-01:00:10:42,402 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:10:43,217 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:00:11:45,051 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:00:12:46,873 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:00:13:49,710 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   6%|▌         | 22/400 [1:30:03<25:30:19, 242.91s/it]2025-03-01:00:15:34,105 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:15:34,887 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   6%|▌         | 23/400 [1:30:55<19:26:57, 185.72s/it]2025-03-01:00:16:26,443 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:16:27,262 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   6%|▌         | 24/400 [1:38:02<26:56:14, 257.91s/it]2025-03-01:00:23:32,746 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:23:33,574 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   6%|▋         | 25/400 [1:40:01<22:31:05, 216.17s/it]2025-03-01:00:25:31,556 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:25:32,473 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   6%|▋         | 26/400 [1:41:37<18:42:51, 180.14s/it]2025-03-01:00:27:07,616 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:27:08,438 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:00:28:10,251 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   7%|▋         | 27/400 [1:47:03<23:12:45, 224.04s/it]2025-03-01:00:32:34,079 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:32:34,900 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:00:33:36,776 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:00:34:38,599 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   7%|▋         | 28/400 [1:50:29<22:35:15, 218.59s/it]2025-03-01:00:35:59,958 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:36:00,788 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   7%|▋         | 29/400 [1:52:59<20:23:38, 197.89s/it]2025-03-01:00:38:29,568 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:38:30,379 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   8%|▊         | 30/400 [1:55:35<19:03:08, 185.37s/it]2025-03-01:00:41:05,728 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:41:06,548 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   8%|▊         | 31/400 [1:58:04<17:52:59, 174.47s/it]2025-03-01:00:43:34,755 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:43:35,574 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   8%|▊         | 32/400 [1:59:39<15:24:40, 150.76s/it]2025-03-01:00:45:10,203 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:45:11,033 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   8%|▊         | 33/400 [2:01:02<13:16:50, 130.27s/it]2025-03-01:00:46:32,670 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:46:33,458 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   8%|▊         | 34/400 [2:01:55<10:53:22, 107.11s/it]2025-03-01:00:47:25,729 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:47:26,542 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   9%|▉         | 35/400 [2:03:27<10:24:00, 102.58s/it]2025-03-01:00:48:57,731 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:48:58,576 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   9%|▉         | 36/400 [2:05:13<10:28:56, 103.67s/it]2025-03-01:00:50:43,952 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:50:44,774 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   9%|▉         | 37/400 [2:08:11<12:41:50, 125.92s/it]2025-03-01:00:53:41,803 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:53:42,623 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  10%|▉         | 38/400 [2:09:39<11:31:51, 114.67s/it]2025-03-01:00:55:10,218 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:55:11,022 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  10%|▉         | 39/400 [2:14:00<15:53:30, 158.48s/it]2025-03-01:00:59:30,907 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:00:59:31,738 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  10%|█         | 40/400 [2:18:13<18:40:54, 186.82s/it]2025-03-01:01:03:43,854 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:03:44,766 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  10%|█         | 41/400 [2:19:38<15:35:39, 156.38s/it]2025-03-01:01:05:09,203 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:05:10,014 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  10%|█         | 42/400 [2:21:05<13:28:54, 135.57s/it]2025-03-01:01:06:36,228 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:06:37,015 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  11%|█         | 43/400 [2:23:04<12:56:42, 130.54s/it]2025-03-01:01:08:35,023 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:08:35,852 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  11%|█         | 44/400 [2:24:36<11:46:32, 119.08s/it]2025-03-01:01:10:07,370 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:10:08,184 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  11%|█▏        | 45/400 [2:26:06<10:52:29, 110.28s/it]2025-03-01:01:11:37,118 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:11:37,902 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  12%|█▏        | 46/400 [2:29:13<13:06:31, 133.31s/it]2025-03-01:01:14:44,158 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:14:44,971 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  12%|█▏        | 47/400 [2:30:06<10:41:52, 109.10s/it]2025-03-01:01:15:36,770 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:15:37,562 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  12%|█▏        | 48/400 [2:34:51<15:49:10, 161.79s/it]2025-03-01:01:20:21,510 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:20:22,307 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  12%|█▏        | 49/400 [2:35:38<12:25:27, 127.43s/it]2025-03-01:01:21:08,757 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:21:09,578 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  12%|█▎        | 50/400 [2:37:01<11:06:14, 114.21s/it]2025-03-01:01:22:32,137 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:22:32,949 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  13%|█▎        | 51/400 [2:41:10<14:59:55, 154.71s/it]2025-03-01:01:26:41,355 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:26:42,167 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  13%|█▎        | 52/400 [2:42:38<13:01:05, 134.67s/it]2025-03-01:01:28:09,254 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:28:10,057 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  13%|█▎        | 53/400 [2:46:38<16:00:42, 166.12s/it]2025-03-01:01:32:08,750 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:32:09,584 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  14%|█▎        | 54/400 [2:49:46<16:36:06, 172.74s/it]2025-03-01:01:35:16,928 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:35:17,741 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  14%|█▍        | 55/400 [2:59:15<27:56:33, 291.57s/it]2025-03-01:01:44:45,794 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:44:46,586 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  14%|█▍        | 56/400 [3:01:42<23:43:47, 248.34s/it]2025-03-01:01:47:13,240 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:47:14,076 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:01:48:15,905 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  14%|█▍        | 57/400 [3:06:11<24:14:51, 254.49s/it]2025-03-01:01:51:42,101 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:51:42,947 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  14%|█▍        | 58/400 [3:07:19<18:52:21, 198.66s/it]2025-03-01:01:52:50,476 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:52:51,291 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  15%|█▍        | 59/400 [3:08:48<15:40:31, 165.49s/it]2025-03-01:01:54:18,563 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:54:19,396 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  15%|█▌        | 60/400 [3:09:56<12:53:16, 136.46s/it]2025-03-01:01:55:27,298 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:55:28,121 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  15%|█▌        | 61/400 [3:11:15<11:13:35, 119.22s/it]2025-03-01:01:56:46,291 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:56:47,118 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  16%|█▌        | 62/400 [3:12:53<10:35:59, 112.90s/it]2025-03-01:01:58:24,439 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:58:25,247 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  16%|█▌        | 63/400 [3:14:22<9:52:54, 105.56s/it] 2025-03-01:01:59:52,884 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:01:59:53,663 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  16%|█▌        | 64/400 [3:18:31<13:52:53, 148.73s/it]2025-03-01:02:04:02,344 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:04:03,188 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  16%|█▋        | 65/400 [3:21:57<15:25:15, 165.72s/it]2025-03-01:02:07:27,699 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:07:28,639 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  16%|█▋        | 66/400 [3:23:04<12:37:32, 136.09s/it]2025-03-01:02:08:34,639 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:08:35,475 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  17%|█▋        | 67/400 [3:28:42<18:11:58, 196.75s/it]2025-03-01:02:14:12,948 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:14:13,769 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  17%|█▋        | 68/400 [3:30:15<15:16:31, 165.64s/it]2025-03-01:02:15:45,985 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:15:46,809 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  17%|█▋        | 69/400 [3:33:32<16:06:05, 175.12s/it]2025-03-01:02:19:03,240 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:19:04,045 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  18%|█▊        | 70/400 [3:34:58<13:35:12, 148.22s/it]2025-03-01:02:20:28,682 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:20:29,517 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  18%|█▊        | 71/400 [3:41:59<21:02:14, 230.20s/it]2025-03-01:02:27:30,159 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:27:31,064 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  18%|█▊        | 72/400 [3:43:14<16:43:09, 183.50s/it]2025-03-01:02:28:44,716 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:28:45,514 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  18%|█▊        | 73/400 [3:44:16<13:21:16, 147.02s/it]2025-03-01:02:29:46,616 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:29:47,419 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  18%|█▊        | 74/400 [3:46:56<13:39:50, 150.89s/it]2025-03-01:02:32:26,536 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:32:27,354 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  19%|█▉        | 75/400 [3:48:30<12:04:53, 133.83s/it]2025-03-01:02:34:00,542 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:34:01,363 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  19%|█▉        | 76/400 [3:50:37<11:51:47, 131.81s/it]2025-03-01:02:36:07,657 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:36:08,482 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  19%|█▉        | 77/400 [3:52:47<11:47:08, 131.36s/it]2025-03-01:02:38:17,952 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:38:18,760 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  20%|█▉        | 78/400 [3:55:18<12:16:56, 137.32s/it]2025-03-01:02:40:49,178 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:40:49,983 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  20%|█▉        | 79/400 [3:56:53<11:05:42, 124.43s/it]2025-03-01:02:42:23,539 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:42:24,354 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  20%|██        | 80/400 [3:58:49<10:50:35, 121.99s/it]2025-03-01:02:44:19,823 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:44:20,643 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  20%|██        | 81/400 [3:59:54<9:17:49, 104.92s/it] 2025-03-01:02:45:24,916 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:45:25,781 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  20%|██        | 82/400 [4:01:58<9:46:28, 110.66s/it]2025-03-01:02:47:28,957 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:47:29,805 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  21%|██        | 83/400 [4:02:56<8:20:57, 94.82s/it] 2025-03-01:02:48:26,823 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:48:27,725 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  21%|██        | 84/400 [4:04:30<8:18:24, 94.63s/it]2025-03-01:02:50:01,027 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:50:01,838 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  21%|██▏       | 85/400 [4:08:02<11:22:10, 129.94s/it]2025-03-01:02:53:33,336 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:53:34,153 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  22%|██▏       | 86/400 [4:09:08<9:38:54, 110.62s/it] 2025-03-01:02:54:38,882 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:54:39,695 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  22%|██▏       | 87/400 [4:10:30<8:52:37, 102.10s/it]2025-03-01:02:56:01,110 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:56:01,887 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  22%|██▏       | 88/400 [4:11:51<8:18:19, 95.83s/it] 2025-03-01:02:57:22,307 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:57:23,116 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  22%|██▏       | 89/400 [4:14:18<9:35:34, 111.04s/it]2025-03-01:02:59:48,852 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:02:59:49,662 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  22%|██▎       | 90/400 [4:17:25<11:31:51, 133.91s/it]2025-03-01:03:02:56,108 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:02:56,935 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  23%|██▎       | 91/400 [4:19:20<11:00:50, 128.32s/it]2025-03-01:03:04:51,381 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:04:52,227 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  23%|██▎       | 92/400 [4:20:14<9:03:07, 105.80s/it] 2025-03-01:03:05:44,653 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:05:45,479 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  23%|██▎       | 93/400 [4:22:26<9:41:40, 113.68s/it]2025-03-01:03:07:56,720 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:07:57,534 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  24%|██▎       | 94/400 [4:24:24<9:47:07, 115.12s/it]2025-03-01:03:09:55,201 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:09:56,165 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  24%|██▍       | 95/400 [4:27:57<12:14:34, 144.51s/it]2025-03-01:03:13:28,269 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:13:29,106 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  24%|██▍       | 96/400 [4:29:59<11:37:32, 137.67s/it]2025-03-01:03:15:30,000 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:15:30,833 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  24%|██▍       | 97/400 [4:31:19<10:07:46, 120.35s/it]2025-03-01:03:16:49,937 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:16:50,795 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  24%|██▍       | 98/400 [4:33:33<10:25:58, 124.37s/it]2025-03-01:03:19:03,672 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:19:04,489 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  25%|██▍       | 99/400 [4:35:00<9:27:27, 113.12s/it] 2025-03-01:03:20:30,532 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:20:31,344 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  25%|██▌       | 100/400 [4:36:07<8:16:59, 99.40s/it]2025-03-01:03:21:37,920 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:21:38,733 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  25%|██▌       | 101/400 [4:43:36<16:57:31, 204.18s/it]2025-03-01:03:29:06,610 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:29:07,390 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  26%|██▌       | 102/400 [4:45:07<14:06:26, 170.42s/it]2025-03-01:03:30:38,256 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:30:39,091 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  26%|██▌       | 103/400 [4:46:54<12:28:22, 151.19s/it]2025-03-01:03:32:24,562 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:32:25,380 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:03:33:27,395 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  26%|██▌       | 104/400 [4:49:48<13:00:16, 158.16s/it]2025-03-01:03:35:19,006 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:35:19,792 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  26%|██▋       | 105/400 [5:00:54<25:27:21, 310.65s/it]2025-03-01:03:46:25,451 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:46:26,270 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  26%|██▋       | 106/400 [5:02:16<19:45:40, 241.98s/it]2025-03-01:03:47:47,190 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:47:48,038 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  27%|██▋       | 107/400 [5:03:29<15:33:23, 191.14s/it]2025-03-01:03:48:59,711 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:49:00,536 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  27%|██▋       | 108/400 [5:04:31<12:21:35, 152.38s/it]2025-03-01:03:50:01,659 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:50:02,469 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  27%|██▋       | 109/400 [5:05:34<10:10:03, 125.79s/it]2025-03-01:03:51:05,388 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:51:06,214 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  28%|██▊       | 110/400 [5:07:20<9:38:23, 119.67s/it] 2025-03-01:03:52:50,774 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:52:51,593 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  28%|██▊       | 111/400 [5:09:46<10:14:37, 127.60s/it]2025-03-01:03:55:16,900 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:55:17,699 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:03:56:19,509 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  28%|██▊       | 112/400 [5:12:08<10:33:28, 131.97s/it]2025-03-01:03:57:39,066 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:57:39,882 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  28%|██▊       | 113/400 [5:13:23<9:08:56, 114.76s/it] 2025-03-01:03:58:53,665 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:03:58:54,488 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  28%|██▊       | 114/400 [5:15:56<10:01:41, 126.23s/it]2025-03-01:04:01:26,649 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:01:27,461 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  29%|██▉       | 115/400 [5:17:17<8:55:45, 112.79s/it] 2025-03-01:04:02:48,090 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:02:48,900 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  29%|██▉       | 116/400 [5:19:17<9:04:37, 115.06s/it]2025-03-01:04:04:48,450 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:04:49,244 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  29%|██▉       | 117/400 [5:20:21<7:49:23, 99.52s/it] 2025-03-01:04:05:51,698 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:05:52,521 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  30%|██▉       | 118/400 [5:24:22<11:08:08, 142.16s/it]2025-03-01:04:09:53,355 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:09:54,166 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  30%|██▉       | 119/400 [5:25:23<9:10:55, 117.63s/it] 2025-03-01:04:10:53,761 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:10:54,548 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  30%|███       | 120/400 [5:30:09<13:05:16, 168.27s/it]2025-03-01:04:15:40,197 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:15:41,117 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  30%|███       | 121/400 [5:30:56<10:12:32, 131.73s/it]2025-03-01:04:16:26,656 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:16:27,476 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  30%|███       | 122/400 [5:32:34<9:23:53, 121.70s/it] 2025-03-01:04:18:04,964 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:18:05,793 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  31%|███       | 123/400 [5:39:00<15:27:17, 200.86s/it]2025-03-01:04:24:30,517 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:24:31,328 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  31%|███       | 124/400 [5:43:39<17:12:21, 224.42s/it]2025-03-01:04:29:09,931 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:29:10,738 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  31%|███▏      | 125/400 [5:46:00<15:13:34, 199.33s/it]2025-03-01:04:31:30,692 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:31:31,523 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  32%|███▏      | 126/400 [5:47:43<12:58:16, 170.42s/it]2025-03-01:04:33:13,681 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:33:14,502 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  32%|███▏      | 127/400 [5:50:06<12:17:51, 162.17s/it]2025-03-01:04:35:36,584 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:35:37,379 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  32%|███▏      | 128/400 [5:51:26<10:24:28, 137.75s/it]2025-03-01:04:36:57,364 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:36:58,175 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  32%|███▏      | 129/400 [5:54:30<11:24:45, 151.61s/it]2025-03-01:04:40:01,294 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:40:02,113 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  32%|███▎      | 130/400 [5:55:34<9:23:15, 125.17s/it] 2025-03-01:04:41:04,772 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:41:05,560 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  33%|███▎      | 131/400 [5:57:55<9:42:28, 129.92s/it]2025-03-01:04:43:25,781 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:43:26,608 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  33%|███▎      | 132/400 [5:59:57<9:29:57, 127.60s/it]2025-03-01:04:45:27,975 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:45:28,798 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  33%|███▎      | 133/400 [6:05:00<13:21:29, 180.11s/it]2025-03-01:04:50:30,601 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:50:31,442 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  34%|███▎      | 134/400 [6:05:59<10:37:31, 143.80s/it]2025-03-01:04:51:29,684 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:51:30,510 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  34%|███▍      | 135/400 [6:07:42<9:40:54, 131.53s/it] 2025-03-01:04:53:12,574 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:53:13,403 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  34%|███▍      | 136/400 [6:09:10<8:41:47, 118.59s/it]2025-03-01:04:54:40,976 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:04:54:41,785 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  34%|███▍      | 137/400 [6:17:37<17:11:13, 235.26s/it]2025-03-01:05:03:08,465 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:03:09,280 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:05:04:11,066 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  34%|███▍      | 138/400 [6:20:22<15:34:12, 213.94s/it]2025-03-01:05:05:52,665 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:05:53,473 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  35%|███▍      | 139/400 [6:22:10<13:13:03, 182.31s/it]2025-03-01:05:07:41,179 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:07:41,982 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  35%|███▌      | 140/400 [6:28:04<16:52:58, 233.76s/it]2025-03-01:05:13:34,996 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:13:35,807 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  35%|███▌      | 141/400 [6:32:34<17:35:47, 244.59s/it]2025-03-01:05:18:04,830 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:18:05,636 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  36%|███▌      | 142/400 [6:34:51<15:13:12, 212.37s/it]2025-03-01:05:20:22,047 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:20:22,966 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  36%|███▌      | 143/400 [6:38:11<14:54:07, 208.75s/it]2025-03-01:05:23:42,327 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:23:43,147 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  36%|███▌      | 144/400 [6:39:08<11:35:53, 163.10s/it]2025-03-01:05:24:38,919 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:24:39,723 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  36%|███▋      | 145/400 [6:41:35<11:12:25, 158.22s/it]2025-03-01:05:27:05,744 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:27:06,558 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  36%|███▋      | 146/400 [6:44:24<11:23:41, 161.50s/it]2025-03-01:05:29:54,914 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:29:55,779 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  37%|███▋      | 147/400 [6:45:50<9:45:13, 138.79s/it] 2025-03-01:05:31:20,703 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:31:21,520 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  37%|███▋      | 148/400 [6:48:16<9:52:23, 141.05s/it]2025-03-01:05:33:47,020 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:33:47,833 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  37%|███▋      | 149/400 [6:51:20<10:43:23, 153.80s/it]2025-03-01:05:36:50,570 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:36:51,394 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:05:37:53,209 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  38%|███▊      | 150/400 [6:54:12<11:04:31, 159.49s/it]2025-03-01:05:39:43,326 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:39:44,170 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  38%|███▊      | 151/400 [6:55:46<9:39:50, 139.72s/it] 2025-03-01:05:41:16,923 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:41:17,742 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  38%|███▊      | 152/400 [6:57:27<8:49:35, 128.13s/it]2025-03-01:05:42:58,009 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:42:58,785 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  38%|███▊      | 153/400 [6:59:41<8:54:30, 129.84s/it]2025-03-01:05:45:11,839 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:45:12,661 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:05:46:14,485 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  38%|███▊      | 154/400 [7:01:39<8:37:38, 126.25s/it]2025-03-01:05:47:09,721 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:47:10,531 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  39%|███▉      | 155/400 [7:02:50<7:27:56, 109.70s/it]2025-03-01:05:48:20,798 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:48:21,610 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  39%|███▉      | 156/400 [7:04:22<7:04:26, 104.37s/it]2025-03-01:05:49:52,741 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:49:53,554 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  39%|███▉      | 157/400 [7:06:15<7:13:18, 106.99s/it]2025-03-01:05:51:45,837 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:51:46,666 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  40%|███▉      | 158/400 [7:07:04<6:01:20, 89.59s/it] 2025-03-01:05:52:34,825 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:52:35,630 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  40%|███▉      | 159/400 [7:08:17<5:40:14, 84.71s/it]2025-03-01:05:53:48,136 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:53:48,964 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  40%|████      | 160/400 [7:09:30<5:25:00, 81.25s/it]2025-03-01:05:55:01,332 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:55:02,151 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  40%|████      | 161/400 [7:10:56<5:29:04, 82.61s/it]2025-03-01:05:56:27,117 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:56:27,922 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  40%|████      | 162/400 [7:12:02<5:07:26, 77.51s/it]2025-03-01:05:57:32,705 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:57:33,509 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  41%|████      | 163/400 [7:12:54<4:36:10, 69.92s/it]2025-03-01:05:58:24,917 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:58:25,729 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  41%|████      | 164/400 [7:14:03<4:34:09, 69.70s/it]2025-03-01:05:59:34,115 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:05:59:34,921 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  41%|████▏     | 165/400 [7:22:56<13:36:44, 208.53s/it]2025-03-01:06:08:26,575 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:08:27,390 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  42%|████▏     | 166/400 [7:24:17<11:04:20, 170.34s/it]2025-03-01:06:09:47,816 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:09:48,666 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  42%|████▏     | 167/400 [7:25:05<8:39:02, 133.66s/it] 2025-03-01:06:10:35,873 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:10:36,706 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  42%|████▏     | 168/400 [7:26:51<8:05:10, 125.48s/it]2025-03-01:06:12:22,266 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:12:23,077 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  42%|████▏     | 169/400 [7:27:43<6:37:40, 103.29s/it]2025-03-01:06:13:13,792 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:13:14,616 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  42%|████▎     | 170/400 [7:28:17<5:16:14, 82.50s/it] 2025-03-01:06:13:47,776 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:13:48,556 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  43%|████▎     | 171/400 [7:29:08<4:39:27, 73.22s/it]2025-03-01:06:14:39,348 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:14:40,165 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  43%|████▎     | 172/400 [7:30:41<5:00:52, 79.18s/it]2025-03-01:06:16:12,426 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:16:13,237 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  43%|████▎     | 173/400 [7:31:55<4:53:18, 77.53s/it]2025-03-01:06:17:26,097 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:17:26,923 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  44%|████▎     | 174/400 [7:32:54<4:31:00, 71.95s/it]2025-03-01:06:18:25,026 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:18:25,835 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  44%|████▍     | 175/400 [7:34:22<4:48:01, 76.81s/it]2025-03-01:06:19:53,173 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:19:53,990 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  44%|████▍     | 176/400 [7:35:02<4:05:38, 65.80s/it]2025-03-01:06:20:33,279 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:20:34,092 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  44%|████▍     | 177/400 [7:36:22<4:19:55, 69.93s/it]2025-03-01:06:21:52,863 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:21:53,769 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  44%|████▍     | 178/400 [7:37:24<4:09:40, 67.48s/it]2025-03-01:06:22:54,617 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:22:55,469 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  45%|████▍     | 179/400 [7:38:24<4:01:13, 65.49s/it]2025-03-01:06:23:55,468 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:23:56,292 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  45%|████▌     | 180/400 [7:39:35<4:06:02, 67.10s/it]2025-03-01:06:25:06,327 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:25:07,173 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  45%|████▌     | 181/400 [7:40:33<3:54:07, 64.14s/it]2025-03-01:06:26:03,564 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:26:04,367 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  46%|████▌     | 182/400 [7:43:47<6:14:58, 103.21s/it]2025-03-01:06:29:17,920 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:29:18,731 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  46%|████▌     | 183/400 [7:45:17<5:59:07, 99.30s/it] 2025-03-01:06:30:48,098 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:30:48,916 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  46%|████▌     | 184/400 [7:46:14<5:11:35, 86.55s/it]2025-03-01:06:31:44,908 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:31:45,756 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  46%|████▋     | 185/400 [7:49:27<7:04:35, 118.49s/it]2025-03-01:06:34:57,926 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:34:58,765 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  46%|████▋     | 186/400 [7:51:47<7:25:53, 125.02s/it]2025-03-01:06:37:18,165 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:37:18,950 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  47%|████▋     | 187/400 [7:57:20<11:04:37, 187.22s/it]2025-03-01:06:42:50,528 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:42:51,345 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  47%|████▋     | 188/400 [7:58:46<9:14:12, 156.85s/it] 2025-03-01:06:44:16,515 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:44:17,337 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  47%|████▋     | 189/400 [8:02:03<9:54:25, 169.03s/it]2025-03-01:06:47:33,972 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:47:34,787 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  48%|████▊     | 190/400 [8:03:21<8:15:55, 141.69s/it]2025-03-01:06:48:51,869 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:48:52,688 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  48%|████▊     | 191/400 [8:05:04<7:33:03, 130.06s/it]2025-03-01:06:50:34,805 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:50:35,631 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  48%|████▊     | 192/400 [8:07:04<7:20:18, 127.01s/it]2025-03-01:06:52:34,692 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:52:35,507 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  48%|████▊     | 193/400 [8:10:13<8:22:35, 145.68s/it]2025-03-01:06:55:43,928 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:55:44,750 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  48%|████▊     | 194/400 [8:11:37<7:17:02, 127.29s/it]2025-03-01:06:57:08,323 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:57:09,148 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  49%|████▉     | 195/400 [8:13:42<7:11:53, 126.40s/it]2025-03-01:06:59:12,654 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:06:59:13,446 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  49%|████▉     | 196/400 [8:19:27<10:52:49, 192.01s/it]2025-03-01:07:04:57,727 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:04:58,548 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  49%|████▉     | 197/400 [8:24:01<12:12:50, 216.61s/it]2025-03-01:07:09:31,733 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:09:32,634 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  50%|████▉     | 198/400 [8:25:17<9:47:52, 174.62s/it] 2025-03-01:07:10:48,383 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:10:49,230 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  50%|████▉     | 199/400 [8:26:55<8:27:33, 151.51s/it]2025-03-01:07:12:25,967 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:12:26,823 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  50%|█████     | 200/400 [8:28:47<7:45:58, 139.79s/it]2025-03-01:07:14:18,422 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:14:19,240 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  50%|█████     | 201/400 [8:31:22<7:58:39, 144.32s/it]2025-03-01:07:16:53,307 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:16:54,118 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  50%|█████     | 202/400 [8:33:07<7:16:53, 132.39s/it]2025-03-01:07:18:37,858 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:18:38,671 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  51%|█████     | 203/400 [8:36:33<8:26:52, 154.38s/it]2025-03-01:07:22:03,545 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:22:04,422 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  51%|█████     | 204/400 [8:42:22<11:35:48, 213.00s/it]2025-03-01:07:27:53,334 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:27:54,254 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  51%|█████▏    | 205/400 [8:44:27<10:06:33, 186.63s/it]2025-03-01:07:29:58,443 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:29:59,259 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  52%|█████▏    | 206/400 [8:46:04<8:36:06, 159.62s/it] 2025-03-01:07:31:35,027 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:31:35,816 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  52%|█████▏    | 207/400 [8:48:28<8:18:28, 154.96s/it]2025-03-01:07:33:59,131 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:33:59,950 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  52%|█████▏    | 208/400 [8:49:58<7:13:34, 135.49s/it]2025-03-01:07:35:29,187 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:35:30,008 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  52%|█████▏    | 209/400 [8:59:54<14:30:27, 273.44s/it]2025-03-01:07:45:24,506 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:45:25,334 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  52%|█████▎    | 210/400 [9:01:57<12:03:48, 228.57s/it]2025-03-01:07:47:28,386 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:47:29,195 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  53%|█████▎    | 211/400 [9:03:09<9:31:39, 181.48s/it] 2025-03-01:07:48:39,980 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:48:40,846 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  53%|█████▎    | 212/400 [9:04:42<8:05:52, 155.06s/it]2025-03-01:07:50:13,412 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:50:14,247 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  53%|█████▎    | 213/400 [9:05:29<6:22:13, 122.64s/it]2025-03-01:07:51:00,387 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:51:01,197 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  54%|█████▎    | 214/400 [9:06:16<5:09:51, 99.96s/it] 2025-03-01:07:51:47,418 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:51:48,239 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  54%|█████▍    | 215/400 [9:07:41<4:54:19, 95.46s/it]2025-03-01:07:53:12,375 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:53:13,166 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  54%|█████▍    | 216/400 [9:09:02<4:39:30, 91.14s/it]2025-03-01:07:54:33,460 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:54:34,255 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  54%|█████▍    | 217/400 [9:11:00<5:02:03, 99.04s/it]2025-03-01:07:56:30,916 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:56:31,725 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  55%|█████▍    | 218/400 [9:12:43<5:03:43, 100.13s/it]2025-03-01:07:58:13,598 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:58:14,406 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  55%|█████▍    | 219/400 [9:13:40<4:23:47, 87.45s/it] 2025-03-01:07:59:11,445 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:59:12,306 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  55%|█████▌    | 220/400 [9:14:25<3:43:37, 74.54s/it]2025-03-01:07:59:55,868 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:07:59:56,678 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  55%|█████▌    | 221/400 [9:16:34<4:31:23, 90.97s/it]2025-03-01:08:02:05,179 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:02:06,047 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  56%|█████▌    | 222/400 [9:17:36<4:03:47, 82.17s/it]2025-03-01:08:03:06,831 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:03:07,655 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  56%|█████▌    | 223/400 [9:18:41<3:47:34, 77.14s/it]2025-03-01:08:04:12,237 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:04:13,029 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  56%|█████▌    | 224/400 [9:22:26<5:56:01, 121.37s/it]2025-03-01:08:07:56,798 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:07:57,624 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  56%|█████▋    | 225/400 [9:25:33<6:51:13, 140.99s/it]2025-03-01:08:11:03,569 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:11:04,398 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  56%|█████▋    | 226/400 [9:26:28<5:34:43, 115.42s/it]2025-03-01:08:11:59,337 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:12:00,137 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  57%|█████▋    | 227/400 [9:27:56<5:09:00, 107.17s/it]2025-03-01:08:13:27,248 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:13:28,080 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  57%|█████▋    | 228/400 [9:30:27<5:44:30, 120.18s/it]2025-03-01:08:15:57,781 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:15:58,595 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  57%|█████▋    | 229/400 [9:33:58<7:00:14, 147.45s/it]2025-03-01:08:19:28,875 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:19:29,661 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  57%|█████▊    | 230/400 [9:34:46<5:33:18, 117.64s/it]2025-03-01:08:20:16,939 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:20:17,746 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  58%|█████▊    | 231/400 [9:35:50<4:45:56, 101.52s/it]2025-03-01:08:21:20,856 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:21:21,689 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  58%|█████▊    | 232/400 [9:37:04<4:20:54, 93.18s/it] 2025-03-01:08:22:34,585 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:22:35,399 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  58%|█████▊    | 233/400 [9:40:13<5:39:56, 122.13s/it]2025-03-01:08:25:44,273 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:25:45,102 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  58%|█████▊    | 234/400 [9:43:24<6:34:25, 142.56s/it]2025-03-01:08:28:54,496 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:28:55,312 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  59%|█████▉    | 235/400 [9:44:33<5:31:30, 120.55s/it]2025-03-01:08:30:03,680 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:30:04,611 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  59%|█████▉    | 236/400 [9:46:43<5:37:38, 123.53s/it]2025-03-01:08:32:14,169 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:32:14,991 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  59%|█████▉    | 237/400 [9:47:32<4:34:33, 101.07s/it]2025-03-01:08:33:02,822 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:33:03,635 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  60%|█████▉    | 238/400 [9:48:51<4:14:46, 94.36s/it] 2025-03-01:08:34:21,544 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:34:22,372 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  60%|█████▉    | 239/400 [9:50:10<4:01:24, 89.96s/it]2025-03-01:08:35:41,242 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:35:42,073 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  60%|██████    | 240/400 [9:51:28<3:50:13, 86.34s/it]2025-03-01:08:36:59,112 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:36:59,892 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  60%|██████    | 241/400 [9:54:56<5:25:02, 122.65s/it]2025-03-01:08:40:26,509 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:40:27,321 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  60%|██████    | 242/400 [9:55:43<4:23:35, 100.10s/it]2025-03-01:08:41:13,973 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:41:14,796 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  61%|██████    | 243/400 [9:56:22<3:34:05, 81.82s/it] 2025-03-01:08:41:53,143 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:41:53,958 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  61%|██████    | 244/400 [9:57:16<3:10:46, 73.37s/it]2025-03-01:08:42:46,807 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:42:47,618 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  61%|██████▏   | 245/400 [9:58:03<2:49:30, 65.61s/it]2025-03-01:08:43:34,315 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:43:35,134 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  62%|██████▏   | 246/400 [9:59:10<2:48:58, 65.84s/it]2025-03-01:08:44:40,673 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:44:41,493 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  62%|██████▏   | 247/400 [10:00:20<2:51:03, 67.08s/it]2025-03-01:08:45:50,655 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:45:51,476 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  62%|██████▏   | 248/400 [10:01:18<2:43:24, 64.50s/it]2025-03-01:08:46:49,146 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:46:49,963 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  62%|██████▏   | 249/400 [10:02:40<2:55:19, 69.66s/it]2025-03-01:08:48:10,853 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:48:11,671 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  62%|██████▎   | 250/400 [10:06:41<5:02:45, 121.11s/it]2025-03-01:08:52:11,991 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:52:12,790 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  63%|██████▎   | 251/400 [10:07:56<4:26:07, 107.17s/it]2025-03-01:08:53:26,635 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:53:27,445 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  63%|██████▎   | 252/400 [10:09:43<4:24:30, 107.23s/it]2025-03-01:08:55:14,025 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:55:14,842 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  63%|██████▎   | 253/400 [10:13:14<5:38:40, 138.24s/it]2025-03-01:08:58:44,601 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:58:45,422 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  64%|██████▎   | 254/400 [10:14:23<4:46:18, 117.66s/it]2025-03-01:08:59:54,259 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:08:59:55,067 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  64%|██████▍   | 255/400 [10:15:16<3:57:36, 98.32s/it] 2025-03-01:09:00:47,441 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:00:48,276 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  64%|██████▍   | 256/400 [10:18:27<5:02:37, 126.09s/it]2025-03-01:09:03:58,333 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:03:59,159 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  64%|██████▍   | 257/400 [10:19:54<4:32:22, 114.28s/it]2025-03-01:09:05:25,061 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:05:25,887 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  64%|██████▍   | 258/400 [10:21:28<4:16:01, 108.18s/it]2025-03-01:09:06:59,012 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:06:59,874 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  65%|██████▍   | 259/400 [10:23:20<4:17:08, 109.42s/it]2025-03-01:09:08:51,335 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:08:52,153 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  65%|██████▌   | 260/400 [10:25:19<4:21:55, 112.25s/it]2025-03-01:09:10:50,181 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:10:51,009 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  65%|██████▌   | 261/400 [10:27:14<4:21:36, 112.92s/it]2025-03-01:09:12:44,671 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:12:45,546 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  66%|██████▌   | 262/400 [10:31:15<5:48:35, 151.56s/it]2025-03-01:09:16:46,398 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:16:47,221 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  66%|██████▌   | 263/400 [10:32:06<4:37:00, 121.32s/it]2025-03-01:09:17:37,133 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:17:37,950 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  66%|██████▌   | 264/400 [10:32:44<3:38:05, 96.22s/it] 2025-03-01:09:18:14,783 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:18:15,574 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  66%|██████▋   | 265/400 [10:35:18<4:15:23, 113.51s/it]2025-03-01:09:20:48,650 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:20:49,438 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  66%|██████▋   | 266/400 [10:39:10<5:33:02, 149.13s/it]2025-03-01:09:24:40,880 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:24:41,693 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  67%|██████▋   | 267/400 [10:41:12<5:12:46, 141.10s/it]2025-03-01:09:26:43,247 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:26:44,078 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  67%|██████▋   | 268/400 [10:42:00<4:08:51, 113.12s/it]2025-03-01:09:27:31,074 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:27:31,917 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  67%|██████▋   | 269/400 [10:43:20<3:45:15, 103.17s/it]2025-03-01:09:28:51,029 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:28:51,988 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  68%|██████▊   | 270/400 [10:46:56<4:56:36, 136.89s/it]2025-03-01:09:32:26,618 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:32:27,435 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  68%|██████▊   | 271/400 [10:48:16<4:17:43, 119.87s/it]2025-03-01:09:33:46,768 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:33:47,703 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  68%|██████▊   | 272/400 [10:55:57<7:54:16, 222.32s/it]2025-03-01:09:41:28,120 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:41:28,947 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  68%|██████▊   | 273/400 [10:59:15<7:34:49, 214.88s/it]2025-03-01:09:44:45,643 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:44:46,451 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  68%|██████▊   | 274/400 [11:01:24<6:37:22, 189.23s/it]2025-03-01:09:46:55,018 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:46:55,843 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  69%|██████▉   | 275/400 [11:01:50<4:51:55, 140.12s/it]2025-03-01:09:47:20,561 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:47:21,372 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  69%|██████▉   | 276/400 [11:03:17<4:17:03, 124.38s/it]2025-03-01:09:48:48,215 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:48:49,030 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  69%|██████▉   | 277/400 [11:04:38<3:48:01, 111.23s/it]2025-03-01:09:50:08,760 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:50:09,602 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  70%|██████▉   | 278/400 [11:06:14<3:37:06, 106.77s/it]2025-03-01:09:51:45,137 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:51:46,027 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:09:52:47,904 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  70%|██████▉   | 279/400 [11:08:43<4:00:33, 119.29s/it]2025-03-01:09:54:13,627 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:54:14,456 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  70%|███████   | 280/400 [11:10:52<4:04:28, 122.24s/it]2025-03-01:09:56:22,738 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:56:23,527 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  70%|███████   | 281/400 [11:12:29<3:47:18, 114.61s/it]2025-03-01:09:57:59,562 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:09:58:00,383 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  70%|███████   | 282/400 [11:16:56<5:15:40, 160.52s/it]2025-03-01:10:02:27,184 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:02:28,010 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:10:03:29,859 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  71%|███████   | 283/400 [11:20:04<5:29:01, 168.73s/it]2025-03-01:10:05:35,088 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:05:35,884 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:10:06:37,710 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  71%|███████   | 284/400 [11:22:23<5:08:54, 159.78s/it]2025-03-01:10:07:53,989 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:07:54,804 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  71%|███████▏  | 285/400 [11:22:54<3:52:18, 121.21s/it]2025-03-01:10:08:25,185 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:08:26,014 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  72%|███████▏  | 286/400 [11:25:03<3:54:52, 123.62s/it]2025-03-01:10:10:34,435 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:10:35,272 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  72%|███████▏  | 287/400 [11:26:32<3:33:06, 113.15s/it]2025-03-01:10:12:03,167 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:12:04,003 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  72%|███████▏  | 288/400 [11:27:40<3:06:03, 99.68s/it] 2025-03-01:10:13:11,398 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:13:12,185 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  72%|███████▏  | 289/400 [11:29:22<3:05:30, 100.28s/it]2025-03-01:10:14:53,083 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:14:53,918 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  72%|███████▎  | 290/400 [11:31:01<3:03:17, 99.98s/it] 2025-03-01:10:16:32,371 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:16:33,191 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  73%|███████▎  | 291/400 [11:33:40<3:33:22, 117.45s/it]2025-03-01:10:19:10,592 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:19:11,405 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  73%|███████▎  | 292/400 [11:35:30<3:27:30, 115.29s/it]2025-03-01:10:21:00,822 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:21:01,660 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  73%|███████▎  | 293/400 [11:46:29<8:16:28, 278.39s/it]2025-03-01:10:31:59,800 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:32:00,626 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  74%|███████▎  | 294/400 [11:47:29<6:16:20, 213.03s/it]2025-03-01:10:33:00,304 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:33:01,131 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  74%|███████▍  | 295/400 [11:49:52<5:36:03, 192.03s/it]2025-03-01:10:35:23,340 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:35:24,214 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  74%|███████▍  | 296/400 [11:51:49<4:53:50, 169.52s/it]2025-03-01:10:37:20,348 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:37:21,292 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-01:10:38:23,089 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  74%|███████▍  | 297/400 [11:55:36<5:20:24, 186.64s/it]2025-03-01:10:41:06,930 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-01:10:41:07,749 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-02:00:53:04,085 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-03-02:00:53:04,087 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-03-02:00:53:04,089 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-03-02:00:53:04,091 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-03-02:00:53:04,093 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-03-02:00:53:15,477 WARNING  [lm_eval.__main__:316]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-02:00:53:15,480 INFO     [lm_eval.__main__:379] Selected Tasks: ['math-500']
2025-03-02:00:53:15,483 INFO     [lm_eval.evaluator:169] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-02:00:53:15,483 INFO     [lm_eval.evaluator:206] Initializing openai-chat-completions model, with arguments: {'model': 'deepseek-reasoner', 'timeout': 30, 'max_retries': 10}
2025-03-02:00:53:15,483 WARNING  [lm_eval.models.openai_completions:117] chat-completions endpoint requires the `--apply_chat_template` flag.
2025-03-02:00:53:15,483 INFO     [lm_eval.models.api_models:117] Using max length 2048 - 1
2025-03-02:00:53:15,483 INFO     [lm_eval.models.api_models:120] Concurrent requests are disabled. To enable concurrent requests, set `num_concurrent` > 1.
2025-03-02:00:53:15,483 INFO     [lm_eval.models.api_models:135] Using tokenizer None
2025-03-02:00:53:15,570 INFO     [lm_eval.evaluator:226] Using cache at ./cache/cache.db_rank0.db
2025-03-02:00:53:20,817 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-03-02:00:53:20,817 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-03-02:00:53:20,906 INFO     [lm_eval.evaluator:271] num_fewshot has been set to 0 for math-500 in its config. Manual configuration will be ignored.
2025-03-02:00:53:20,907 WARNING  [lm_eval.evaluator:421] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-03-02:00:53:20,970 INFO     [lm_eval.evaluator:517] Running generate_until requests
2025-03-02:00:53:20,970 INFO     [lm_eval.api.model:261] Loading 'generate_until' responses from cache './cache/cache.db_rank0.db' where possible...

Checking cached requests:   0%|          | 0/500 [00:00<?, ?it/s]
Checking cached requests:  18%|█▊        | 91/500 [00:00<00:00, 909.57it/s]
Checking cached requests:  39%|███▉      | 196/500 [00:00<00:00, 990.15it/s]
Checking cached requests:  59%|█████▉    | 296/500 [00:00<00:00, 983.79it/s]
Checking cached requests:  79%|███████▉  | 395/500 [00:00<00:00, 974.09it/s]
Checking cached requests: 100%|██████████| 500/500 [00:00<00:00, 1174.12it/s]
2025-03-02:00:53:21,397 INFO     [lm_eval.api.model:285] Cached requests: 397, Requests remaining: 103

Requesting API:   0%|          | 0/103 [00:00<?, ?it/s]2025-03-02:00:53:21,400 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:00:53:21,401 WARNING  [lm_eval.models.api_models:293] Cannot determine EOS string to pass to stop sequence. Manually set by passing `eos_string` to model_args.
2025-03-02:00:53:22,400 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   1%|          | 1/103 [01:13<2:05:22, 73.75s/it]2025-03-02:00:54:35,146 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:00:54:36,027 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   2%|▏         | 2/103 [02:56<2:33:05, 90.94s/it]2025-03-02:00:56:18,124 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:00:56:18,952 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   3%|▎         | 3/103 [03:36<1:52:47, 67.67s/it]2025-03-02:00:56:58,109 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:00:56:58,979 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   4%|▍         | 4/103 [14:37<8:18:07, 301.89s/it]2025-03-02:01:07:59,062 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:07:59,900 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   5%|▍         | 5/103 [20:55<8:58:06, 329.46s/it]2025-03-02:01:14:17,388 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:14:18,231 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   6%|▌         | 6/103 [22:17<6:36:18, 245.14s/it]2025-03-02:01:15:38,859 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:15:39,681 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   7%|▋         | 7/103 [26:05<6:23:13, 239.51s/it]2025-03-02:01:19:26,787 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:19:27,621 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   8%|▊         | 8/103 [26:59<4:45:32, 180.34s/it]2025-03-02:01:20:20,418 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:20:21,243 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:   9%|▊         | 9/103 [28:12<3:50:01, 146.82s/it]2025-03-02:01:21:33,536 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:21:34,318 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  10%|▉         | 10/103 [29:24<3:11:51, 123.78s/it]2025-03-02:01:22:45,739 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:22:46,563 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  11%|█         | 11/103 [31:11<3:02:04, 118.74s/it]2025-03-02:01:24:33,055 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:24:33,881 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-03-02:01:25:35,715 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  12%|█▏        | 12/103 [34:42<3:42:43, 146.85s/it]2025-03-02:01:28:04,184 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:28:05,347 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  13%|█▎        | 13/103 [36:41<3:27:16, 138.18s/it]2025-03-02:01:30:02,422 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:30:03,299 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  14%|█▎        | 14/103 [38:26<3:10:19, 128.30s/it]2025-03-02:01:31:47,901 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:31:48,729 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  15%|█▍        | 15/103 [39:53<2:50:02, 115.93s/it]2025-03-02:01:33:15,168 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:33:15,971 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  16%|█▌        | 16/103 [42:52<3:15:32, 134.86s/it]2025-03-02:01:36:13,982 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:36:14,795 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  17%|█▋        | 17/103 [43:36<2:34:07, 107.52s/it]2025-03-02:01:36:57,930 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:36:58,780 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  17%|█▋        | 18/103 [44:56<2:20:30, 99.18s/it] 2025-03-02:01:38:17,682 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:38:18,507 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  18%|█▊        | 19/103 [47:07<2:32:19, 108.80s/it]2025-03-02:01:40:28,906 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:40:29,828 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  19%|█▉        | 20/103 [50:51<3:18:29, 143.49s/it]2025-03-02:01:44:13,242 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:44:14,047 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  20%|██        | 21/103 [52:09<2:49:00, 123.66s/it]2025-03-02:01:45:30,666 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:45:31,502 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  21%|██▏       | 22/103 [53:31<2:30:11, 111.26s/it]2025-03-02:01:46:53,007 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:46:53,843 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  22%|██▏       | 23/103 [56:01<2:43:50, 122.88s/it]2025-03-02:01:49:22,981 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:49:23,803 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  23%|██▎       | 24/103 [57:07<2:19:23, 105.87s/it]2025-03-02:01:50:29,188 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:50:30,005 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  24%|██▍       | 25/103 [1:01:00<3:07:08, 143.96s/it]2025-03-02:01:54:21,997 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:01:54:22,893 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  25%|██▌       | 26/103 [1:12:54<6:44:13, 314.98s/it]2025-03-02:02:06:15,977 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:06:16,923 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  26%|██▌       | 27/103 [1:14:54<5:24:59, 256.57s/it]2025-03-02:02:08:16,279 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:08:17,132 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  27%|██▋       | 28/103 [1:15:50<4:05:11, 196.16s/it]2025-03-02:02:09:11,476 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:09:12,294 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  28%|██▊       | 29/103 [1:19:59<4:21:43, 212.20s/it]2025-03-02:02:13:21,115 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:13:21,975 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  29%|██▉       | 30/103 [1:20:56<3:21:30, 165.63s/it]2025-03-02:02:14:18,066 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:14:18,868 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  30%|███       | 31/103 [1:21:42<2:35:36, 129.68s/it]2025-03-02:02:15:03,869 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:15:04,704 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  31%|███       | 32/103 [1:23:43<2:30:17, 127.01s/it]2025-03-02:02:17:04,638 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:17:05,421 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  32%|███▏      | 33/103 [1:25:31<2:21:44, 121.49s/it]2025-03-02:02:18:53,245 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:18:54,126 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  33%|███▎      | 34/103 [1:26:05<1:49:34, 95.28s/it] 2025-03-02:02:19:27,387 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:19:28,211 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  34%|███▍      | 35/103 [1:29:50<2:31:49, 133.97s/it]2025-03-02:02:23:11,621 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:23:12,465 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  35%|███▍      | 36/103 [1:33:34<2:59:53, 161.09s/it]2025-03-02:02:26:56,008 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:26:56,832 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  36%|███▌      | 37/103 [1:35:26<2:41:00, 146.37s/it]2025-03-02:02:28:48,008 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:28:48,879 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  37%|███▋      | 38/103 [1:36:43<2:15:54, 125.45s/it]2025-03-02:02:30:04,658 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:30:05,438 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  38%|███▊      | 39/103 [1:37:52<1:55:56, 108.70s/it]2025-03-02:02:31:14,279 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:31:15,061 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  39%|███▉      | 40/103 [1:39:24<1:48:43, 103.55s/it]2025-03-02:02:32:45,811 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:32:46,737 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  40%|███▉      | 41/103 [1:40:23<1:33:12, 90.20s/it] 2025-03-02:02:33:44,849 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:33:45,659 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  41%|████      | 42/103 [1:41:54<1:31:59, 90.49s/it]2025-03-02:02:35:16,018 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:35:16,852 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  42%|████▏     | 43/103 [1:44:12<1:44:40, 104.68s/it]2025-03-02:02:37:33,817 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:37:34,636 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  43%|████▎     | 44/103 [1:45:32<1:35:35, 97.22s/it] 2025-03-02:02:38:53,614 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:38:54,441 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  44%|████▎     | 45/103 [1:46:18<1:19:11, 81.92s/it]2025-03-02:02:39:39,835 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:39:40,674 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  45%|████▍     | 46/103 [1:47:20<1:12:18, 76.11s/it]2025-03-02:02:40:42,387 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:40:43,167 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  46%|████▌     | 47/103 [1:48:17<1:05:25, 70.10s/it]2025-03-02:02:41:38,462 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:41:39,284 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  47%|████▋     | 48/103 [2:04:45<5:16:51, 345.66s/it]2025-03-02:02:58:07,092 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:02:58:07,936 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  48%|████▊     | 49/103 [2:07:09<4:16:39, 285.17s/it]2025-03-02:03:00:31,122 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:00:31,926 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  49%|████▊     | 50/103 [2:08:36<3:19:17, 225.61s/it]2025-03-02:03:01:57,767 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:01:58,596 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  50%|████▉     | 51/103 [2:09:11<2:26:05, 168.56s/it]2025-03-02:03:02:33,214 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:02:34,123 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  50%|█████     | 52/103 [2:10:25<1:59:04, 140.08s/it]2025-03-02:03:03:46,843 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:03:47,678 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  51%|█████▏    | 53/103 [2:11:15<1:34:15, 113.10s/it]2025-03-02:03:04:36,985 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:04:37,768 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  52%|█████▏    | 54/103 [2:12:33<1:23:48, 102.63s/it]2025-03-02:03:05:55,180 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:05:56,068 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  53%|█████▎    | 55/103 [2:13:48<1:15:24, 94.25s/it] 2025-03-02:03:07:09,894 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:07:10,738 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  54%|█████▍    | 56/103 [2:14:52<1:06:40, 85.11s/it]2025-03-02:03:08:13,679 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:08:14,700 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  55%|█████▌    | 57/103 [2:16:01<1:01:31, 80.25s/it]2025-03-02:03:09:22,597 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:09:23,431 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  56%|█████▋    | 58/103 [2:18:39<1:17:46, 103.69s/it]2025-03-02:03:12:00,968 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:12:01,774 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  57%|█████▋    | 59/103 [2:19:34<1:05:22, 89.15s/it] 2025-03-02:03:12:56,199 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:12:56,995 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  58%|█████▊    | 60/103 [2:21:58<1:15:34, 105.45s/it]2025-03-02:03:15:19,681 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:15:20,509 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  59%|█████▉    | 61/103 [2:22:48<1:02:18, 89.01s/it] 2025-03-02:03:16:10,344 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:16:11,151 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  60%|██████    | 62/103 [2:23:43<53:45, 78.68s/it]  2025-03-02:03:17:04,918 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:17:05,818 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  61%|██████    | 63/103 [2:24:59<51:56, 77.90s/it]2025-03-02:03:18:20,998 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:18:21,818 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  62%|██████▏   | 64/103 [2:33:34<2:15:48, 208.94s/it]2025-03-02:03:26:55,679 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:26:56,500 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  63%|██████▎   | 65/103 [2:34:54<1:47:48, 170.23s/it]2025-03-02:03:28:15,599 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:28:16,413 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  64%|██████▍   | 66/103 [2:37:02<1:37:17, 157.77s/it]2025-03-02:03:30:24,301 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:30:25,175 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  65%|██████▌   | 67/103 [2:37:43<1:13:34, 122.62s/it]2025-03-02:03:31:04,901 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:31:05,715 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  66%|██████▌   | 68/103 [2:38:50<1:01:52, 106.08s/it]2025-03-02:03:32:12,382 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:32:13,210 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  67%|██████▋   | 69/103 [2:39:33<49:21, 87.11s/it]   2025-03-02:03:32:55,216 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:32:56,049 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  68%|██████▊   | 70/103 [2:42:17<1:00:33, 110.11s/it]2025-03-02:03:35:38,990 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:35:39,804 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  69%|██████▉   | 71/103 [2:44:26<1:01:44, 115.75s/it]2025-03-02:03:37:47,916 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:37:48,769 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  70%|██████▉   | 72/103 [2:46:48<1:03:49, 123.55s/it]2025-03-02:03:40:09,648 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:40:10,464 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  71%|███████   | 73/103 [2:48:17<56:40, 113.35s/it]  2025-03-02:03:41:39,214 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:41:40,020 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  72%|███████▏  | 74/103 [2:50:39<58:53, 121.83s/it]2025-03-02:03:44:00,821 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:44:01,633 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  73%|███████▎  | 75/103 [2:51:22<45:51, 98.28s/it] 2025-03-02:03:44:44,166 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:44:44,995 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  74%|███████▍  | 76/103 [2:52:19<38:34, 85.71s/it]2025-03-02:03:45:40,530 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:45:41,357 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  75%|███████▍  | 77/103 [2:54:13<40:55, 94.42s/it]2025-03-02:03:47:35,296 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:47:36,134 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  76%|███████▌  | 78/103 [2:55:19<35:42, 85.72s/it]2025-03-02:03:48:40,699 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:48:41,513 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  77%|███████▋  | 79/103 [2:57:41<41:05, 102.71s/it]2025-03-02:03:51:03,052 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:51:03,907 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  78%|███████▊  | 80/103 [2:58:24<32:27, 84.67s/it] 2025-03-02:03:51:45,619 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:51:46,453 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  79%|███████▊  | 81/103 [2:59:30<29:03, 79.26s/it]2025-03-02:03:52:52,253 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:03:52:53,064 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  80%|███████▉  | 82/103 [3:07:31<1:09:54, 199.72s/it]2025-03-02:04:00:53,070 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:00:53,888 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  81%|████████  | 83/103 [3:08:56<55:02, 165.14s/it]  2025-03-02:04:02:17,527 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:02:18,368 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  82%|████████▏ | 84/103 [3:11:09<49:14, 155.48s/it]2025-03-02:04:04:30,443 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:04:31,248 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  83%|████████▎ | 85/103 [3:14:37<51:26, 171.45s/it]2025-03-02:04:07:59,181 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:08:00,013 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  83%|████████▎ | 86/103 [3:16:08<41:44, 147.30s/it]2025-03-02:04:09:30,121 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:09:30,958 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  84%|████████▍ | 87/103 [3:17:38<34:39, 129.96s/it]2025-03-02:04:10:59,629 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:11:00,554 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  85%|████████▌ | 88/103 [3:19:34<31:29, 125.95s/it]2025-03-02:04:12:56,225 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:12:57,048 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  86%|████████▋ | 89/103 [3:23:00<34:56, 149.75s/it]2025-03-02:04:16:21,510 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:16:22,336 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  87%|████████▋ | 90/103 [3:28:49<45:25, 209.63s/it]2025-03-02:04:22:10,860 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:22:11,692 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  88%|████████▊ | 91/103 [3:30:02<33:44, 168.67s/it]2025-03-02:04:23:23,956 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:23:24,787 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  89%|████████▉ | 92/103 [3:30:35<23:28, 128.04s/it]2025-03-02:04:23:57,192 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:23:58,004 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  90%|█████████ | 93/103 [3:32:22<20:16, 121.68s/it]2025-03-02:04:25:44,031 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:25:44,850 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  91%|█████████▏| 94/103 [3:38:15<28:38, 190.93s/it]2025-03-02:04:31:36,542 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:31:37,375 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  92%|█████████▏| 95/103 [3:39:16<20:17, 152.19s/it]2025-03-02:04:32:38,335 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:32:39,122 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  93%|█████████▎| 96/103 [3:40:02<14:01, 120.25s/it]2025-03-02:04:33:24,078 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:33:24,904 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  94%|█████████▍| 97/103 [3:42:35<13:00, 130.05s/it]2025-03-02:04:35:56,968 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:35:57,780 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  95%|█████████▌| 98/103 [3:46:24<13:18, 159.64s/it]2025-03-02:04:39:45,657 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:39:46,475 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  96%|█████████▌| 99/103 [3:48:05<09:27, 141.98s/it]2025-03-02:04:41:26,431 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:41:27,242 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  97%|█████████▋| 100/103 [3:49:13<05:59, 119.87s/it]2025-03-02:04:42:34,717 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:42:35,566 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  98%|█████████▊| 101/103 [3:56:20<07:04, 212.21s/it]2025-03-02:04:49:42,392 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:49:43,202 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API:  99%|█████████▉| 102/103 [3:58:29<03:07, 187.19s/it]2025-03-02:04:51:51,210 INFO     [lm_eval.models.api_models:622] Tokenized requests are disabled. Context + generation length is not checked.
2025-03-02:04:51:52,044 INFO     [httpx:1026] HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"

Requesting API: 100%|██████████| 103/103 [4:01:45<00:00, 189.60s/it]
Requesting API: 100%|██████████| 103/103 [4:01:45<00:00, 140.83s/it]
2025-03-02:04:55:19,413 INFO     [lm_eval.loggers.evaluation_tracker:209] Saving results aggregated
2025-03-02:04:55:19,465 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: math-500
openai-chat-completions (model=deepseek-reasoner,timeout=30,max_retries=10), gen_kwargs: (None), limit: 500.0, num_fewshot: 0, batch_size: 1
| Tasks  |Version|  Filter  |n-shot|  Metric   |   |Value|   |Stderr|
|--------|------:|----------|-----:|-----------|---|----:|---|-----:|
|math-500|      1|get-answer|     0|exact_match|↑  | 0.69|±  |0.0207|
2025-03-02:17:00:49,386 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-03-02:17:00:49,389 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-03-02:17:00:49,391 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-03-02:17:00:49,392 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-03-02:17:00:49,394 INFO     [lm_eval.tasks:460] The tag 'kobest' is already registered as a group, this tag will not be registered. This may affect tasks you want to call.
2025-03-02:17:01:02,986 WARNING  [lm_eval.__main__:316]  --limit SHOULD ONLY BE USED FOR TESTING.REAL METRICS SHOULD NOT BE COMPUTED USING LIMIT.
2025-03-02:17:01:02,988 INFO     [lm_eval.__main__:379] Selected Tasks: ['math-500']
2025-03-02:17:01:02,990 INFO     [lm_eval.evaluator:169] Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234
2025-03-02:17:01:02,990 INFO     [lm_eval.evaluator:206] Initializing openai-chat-completions model, with arguments: {'model': 'deepseek-reasoner', 'timeout': 30, 'max_retries': 10}
2025-03-02:17:01:02,990 WARNING  [lm_eval.models.openai_completions:117] chat-completions endpoint requires the `--apply_chat_template` flag.
2025-03-02:17:01:02,990 INFO     [lm_eval.models.api_models:117] Using max length 2048 - 1
2025-03-02:17:01:02,990 INFO     [lm_eval.models.api_models:120] Concurrent requests are disabled. To enable concurrent requests, set `num_concurrent` > 1.
2025-03-02:17:01:02,990 INFO     [lm_eval.models.api_models:135] Using tokenizer None
2025-03-02:17:01:03,086 INFO     [lm_eval.evaluator:226] Using cache at ./cache/cache.db_rank0.db
2025-03-02:17:01:09,035 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-03-02:17:01:09,035 WARNING  [lm_eval.api.task:327] [Task: math-500] has_training_docs and has_validation_docs are False, using test_docs as fewshot_docs but this is not recommended.
2025-03-02:17:01:09,103 INFO     [lm_eval.evaluator:271] num_fewshot has been set to 0 for math-500 in its config. Manual configuration will be ignored.
2025-03-02:17:01:09,103 WARNING  [lm_eval.evaluator:421] Chat template formatting change affects loglikelihood and multiple-choice tasks. See docs/chat-template-readme.md for details.
2025-03-02:17:01:09,109 INFO     [lm_eval.evaluator:517] Running generate_until requests
2025-03-02:17:01:09,110 INFO     [lm_eval.api.model:261] Loading 'generate_until' responses from cache './cache/cache.db_rank0.db' where possible...
{'x=5': '5', '1-2': '-21', '11\\sqrt2': '11\\sqrt{2}', '\\begin{pmatrix}-1/3\\\\2/3\\\\5/3\\end{pmatrix}': '\\begin{pmatrix}-\\frac{1}{3}\\\\\\frac{2}{3}\\\\\\frac{5}{3}\\end{pmatrix}', '\\frac43': '\\frac{4}{3}', '4210_{5}': '4210_5', '\\frac65': '\\frac{6}{5}', '\\frac{270}7\\text{degrees}': '\\frac{270}{7}', '.0000672': '0.0000672', '11\\!111\\!111\\!100': '11111111100', '\\text{(C)}': 'C', '\\frac59': '\\frac{5}{9}', '\\32\\!348': '34348', '\\text{(E)}': 'E', '864\\mbox{inches}^2': '864', '\\text{(B)}': 'B', '5.4\\text{cents}': '5.4', '\\frac9{19}': '\\frac{9}{19}', '1+2\\sqrt{3}': '2\\sqrt{3}+1', '\\frac{11+9a}{20}': '\\frac{9a+11}{20}', '\\frac{9}{100}': '0.09', '11\\sqrt{5}+11': '11(1+\\sqrt{5})', '\\frac14': '\\frac{1}{4}', 'x\\in[-27]': '[-27]', '\\frac34': '\\frac{3}{4}', '\\begin{pmatrix}1/5\\\\-18/5\\end{pmatrix}': '\\begin{pmatrix}\\frac{1}{5}\\\\-\\frac{18}{5}\\end{pmatrix}', '\\begin{pmatrix}16/49\\\\48/49\\\\24/49\\end{pmatrix}': '\\begin{pmatrix}\\frac{16}{49}\\\\\\frac{48}{49}\\\\\\frac{24}{49}\\end{pmatrix}', '.35625': '0.35625', '\\$18.90': '18.90', '15\\mbox{cm}^2': '15', '\\36': '36', '2516_8': '2156', '10\\!080': '10080', '\\$32\\!348': '32348', '\\$36': '36'}

Checking cached requests:   0%|          | 0/500 [00:00<?, ?it/s]
Checking cached requests:  19%|█▊        | 93/500 [00:00<00:00, 924.01it/s]
Checking cached requests:  44%|████▍     | 220/500 [00:00<00:00, 1123.72it/s]
Checking cached requests:  67%|██████▋   | 333/500 [00:00<00:00, 1069.04it/s]
Checking cached requests:  88%|████████▊ | 441/500 [00:00<00:00, 1057.22it/s]
Checking cached requests: 100%|██████████| 500/500 [00:00<00:00, 976.51it/s] 
2025-03-02:17:01:09,676 INFO     [lm_eval.api.model:285] Cached requests: 500, Requests remaining: 0
['(3\\frac{\\pi}{2})']
['(3\\frac{\\pi}{2})']
['p-q']
['p-q']
['\\frac{14}{3}']
['\\frac{14}{3}']
['9']
['9']
['evelyn']
['evelyn']
['42']
['42']
['27']
['27']
['90']
['90']
['3\\sqrt{13}']
['3\\sqrt{13}']
['5']
['4']
['2220']
['2220']
['\\frac{3}{56}']
['\\frac{3}{56}']
['284']
['284']
['5']
['5']
['\\sqrt{51}']
['\\sqrt{51}']
['6-5i']
['6-5i']
['-50']
['-50']
['\\pi']
['\\pi']
['28']
['28']
['3']
['3']
['6+9i']
['6+9i']
['13535']
['13535']
['5']
['5']
['5']
['5']
['10']
['10']
['-21']
['-21']
['144']
['144']
['78']
['78']
['-2+7i']
['-2+7i']
['225']
['225']
['52_8']
['52_8']
['11\\sqrt{2}']
['11\\sqrt{2}']
['720']
['720']
['\\frac{243}{625}']
['\\frac{243}{625}']
['-125']
['-125']
['3']
['3']
['3']
['357']
['72']
['72']
['2000']
['2000']
['23']
['23']
['12']
['12']
['17']
['17']
['4']
['4']
['100']
['70\\sqrt{2}']
['1.25']
['1.25']
['2']
['2']
['6']
['6']
['5']
['5']
['\\frac{3}{2}']
['\\frac{3}{2}']
['83']
['83']
['203']
['203']
['x^5-x^4+x^3-x^2+x-1']
['x^5-x^4+x^3-x^2+x-1']
['12']
['12']
['-\\frac{\\pi}{6}']
['-\\frac{\\pi}{6}']
['0.15']
['0.15']
['3']
['3']
['11']
['11']
['16']
['16']
['9901']
['9901']
['5']
['5']
['(631-1)']
['(631-1)']
['-256']
['-256']
['4']
['4']
['10']
['10']
['\\frac{35}{64}']
['\\frac{35}{64}']
['1']
['1']
['x^3+3x-6']
['x^3+3x-6']
['10']
['10']
['46']
['46']
['-1']
['-1']
['40_9']
['40_9']
['2516']
['2156']
['3']
['3']
['[invalid]']
['\\frac{3\\sqrt{3}}{4}']
['\\cotx']
['\\cotx']
['\\frac{11}{36}']
['\\frac{11}{36}']
['0']
['0']
['4']
['4']
['(-21)']
['(-21)']
['2']
['2']
['501']
['501']
['3']
['3']
['\\frac{3}{2}']
['\\frac{3}{2}']
['2']
['2']
['-1']
['-1']
['\\sqrt{5}']
['\\sqrt{5}']
['240']
['240']
['1']
['1']
['2']
['2']
['21']
['21']
['\\frac{3}{2}']
['\\frac{3}{2}']
['1']
['1']
['\\frac{448}{15625}']
['\\frac{448}{15625}']
['33']
['33']
['130']
['80']
['-4']
['-4']
['1+\\sqrt{19}']
['1\\pm\\sqrt{19}']
['[invalid]']
['east']
['2k+2']
['2k+2']
['\\begin{pmatrix}-\\frac{1}{3}\\\\\\frac{2}{3}\\\\\\frac{5}{3}\\end{pmatrix}']
['\\begin{pmatrix}-\\frac{1}{3}\\\\\\frac{2}{3}\\\\\\frac{5}{3}\\end{pmatrix}']
['145']
['145']
['850']
['850']
['(a+5)(b+2)']
['(a+5)(b+2)']
['(34]']
['(34]']
['40']
['40']
['29']
['29']
['\\frac{4}{3}']
['\\frac{4}{3}']
['9']
['9']
['2']
['2']
['120']
['120']
['504']
['504']
['210']
['210']
['13']
['13']
['8000']
['8000']
['-5']
['-5']
['1260']
['1260']
['2']
['2']
['3']
['3']
['81']
['81']
['-9']
['-9']
['even']
['even']
['6']
['6']
['9']
['9']
['8']
['8']
['\\frac{11}{2}']
['\\frac{11}{2}']
['-3']
['-3']
['1+274i']
['1+274i']
['4210_5']
['4210_5']
['36']
['36']
['\\frac{3840}{289}']
['\\frac{3840}{289}']
['13']
['13']
['8']
['8']
['4']
['4']
['120']
['120']
['16']
['16']
['9']
['9']
['64']
['64']
['204_5']
['204_5']
['\\frac{1}{3}']
['\\frac{1}{3}']
['1']
['1']
['13']
['13']
['2']
['2']
['28800']
['28800']
['3\\sqrt{5}']
['3\\sqrt{5}']
['(15-29)']
['(15-29)']
['-2']
['-2']
['[invalid]']
['\\frac{\\sqrt{3}}{3}']
['16']
['16']
['11']
['11']
['49']
['49']
['1']
['1']
['144']
['144']
['8']
['8']
['\\frac{2}{21}']
['\\frac{2}{21}']
['10\\sqrt{2}']
['2\\sqrt{113}']
['\\frac{1}{4}']
['\\frac{1}{4}']
['30']
['30']
['\\frac{6}{5}']
['\\frac{6}{5}']
['2107']
['2107']
['3.21']
['3.21']
['18']
['18']
['6']
['6']
['\\frac{17}{50}']
['\\frac{17}{50}']
['-\\frac{35}{9}']
['-\\frac{35}{9}']
['-\\sqrt{3}']
['-\\sqrt{3}']
['\\frac{4}{9}']
['\\frac{4}{9}']
['\\frac{270}{7}']
['\\frac{270}{7}']
['65']
['65']
['19']
['19']
['12']
['12']
['1736']
['1736']
['\\frac{13}{15}']
['\\frac{13}{15}']
['350']
['350']
['4']
['4']
['2']
['2']
['3']
['3']
['0.0000672']
['0.0000672']
['30']
['30']
['60']
['60']
['5x-7y+11z+4=0']
['5x-7y+11z+4=0']
['3']
['3']
['[invalid]']
['\\frac{\\sqrt{3}}{3}']
['1251']
['1251']
['23']
['23']
['[2\\infty)']
['(2\\infty)']
['1']
['1']
['7']
['7']
['7']
['7']
['6']
['6']
['160']
['160']
['\\frac{13}{18}']
['\\frac{13}{18}']
['0']
['0']
['30']
['30']
['4']
['4']
['\\frac{1}{4}']
['\\frac{1}{4}']
['24']
['24']
['1600']
['1600']
['6']
['6']
['10080']
['10080']
['17']
['17']
['40']
['40']
['66']
['66']
['\\frac{2}{3}']
['\\frac{2}{3}']
['12']
['12']
['\\frac{64}{27}']
['0']
['\\begin{pmatrix}-2\\\\-14\\\\-7\\end{pmatrix}']
['\\begin{pmatrix}-2\\\\-14\\\\-7\\end{pmatrix}']
['(\\frac{3}{2}-13)']
['(\\frac{3}{2}-13)']
['28']
['28']
['1']
['1']
['16']
['16']
['10']
['10']
['5']
['5']
['56']
['56']
['2']
['2']
['110']
['110']
['2']
['2']
['6']
['6']
['11111111100']
['11111111100']
['(-16)']
['(-16)']
['\\frac{1}{2}']
['\\frac{1}{2}']
['\\frac{16}{27}']
['\\frac{16}{27}']
['900']
['900']
['54']
['54']
['14']
['14']
['\\frac{9}{256}']
['\\frac{9}{256}']
['11']
['11']
['3']
['3']
['c']
['c']
['288\\pi']
['288\\pi']
['90']
['90']
['\\frac{16}{5}']
['\\frac{16}{5}']
['10']
['10']
['\\frac{1997}{2}']
['\\frac{1997}{2}']
['30']
['30']
['34']
['34']
['\\frac{5}{9}']
['\\frac{5}{9}']
['12']
['12']
['22']
['22']
['-4']
['-4']
['16']
['16']
['154']
['116']
['17']
['17']
['32348']
['32348']
['3']
['3']
['8']
['8']
['-13x+3']
['-13x+3']
['8']
['8']
['\\frac{10}{11}']
['\\frac{10}{11}']
['\\begin{pmatrix}-1&0\\\\0&-1\\end{pmatrix}']
['\\begin{pmatrix}-1&0\\\\0&-1\\end{pmatrix}']
['17']
['17']
['13']
['13']
['540']
['540']
['81']
['81']
['\\frac{1}{8}']
['\\frac{1}{8}']
['28']
['28']
['e']
['e']
['\\frac{8}{21}']
['\\frac{8}{21}']
['864']
['864']
['16']
['16']
['22']
['22']
['120']
['120']
['76']
['76']
['4']
['4']
['15']
['15']
['4\\frac{4}{5}']
['1\\frac{4}{5}']
['4005']
['4005']
['\\frac{33}{100}']
['\\frac{33}{100}']
['180']
['180']
['1']
['1']
['6']
['6']
['10']
['10']
['333']
['333']
['1030']
['1030']
['1250']
['1250']
['18+2\\pi']
['18+2\\pi']
['7']
['7']
['11']
['11']
['\\sqrt{53}']
['\\sqrt{53}']
['255']
['255']
['7\\pi']
['7\\pi']
['8']
['8']
['36']
['36']
['129']
['129']
['1']
['1']
['3-2\\sqrt{2}']
['3\\pm2\\sqrt{2}']
['440']
['440']
['\\frac{17}{21}']
['\\frac{17}{21}']
['36']
['36']
['7']
['7']
['16']
['16']
['4']
['4']
['63']
['63']
['898']
['898']
['(\\frac{3}{5}\\frac{8}{3}]']
['(\\frac{3}{5}\\frac{8}{3}]']
['58']
['58']
['11']
['11']
['b']
['b']
['103']
['103']
['\\begin{pmatrix}-18\\\\-49\\\\96\\end{pmatrix}']
['\\begin{pmatrix}-18\\\\-49\\\\96\\end{pmatrix}']
['63']
['63']
['12']
['12']
['5.4']
['5.4']
['5']
['5']
['28']
['28']
['9']
['9']
['\\frac{9}{19}']
['\\frac{9}{19}']
['4']
['6']
['(-\\infty0]']
['(-\\infty0]']
['2\\sqrt{3}+1']
['2\\sqrt{3}+1']
['14']
['14']
['49']
['49']
['3']
['3']
['(5\\infty)']
['(5\\infty)']
['12\\pi']
['12\\pi']
['(24)']
['(24)']
['41']
['41']
['12']
['12']
['0']
['0']
['\\frac{9a+11}{20}']
['\\frac{9a+11}{20}']
['-128']
['-128']
['-\\frac{24}{25}']
['-\\frac{24}{25}']
['10']
['10']
['-1']
['-1']
['\\frac{1}{3}']
['\\frac{1}{3}']
['150']
['120']
['4']
['4']
['0.09']
['0.09']
['15']
['15']
['3']
['3']
['4']
['4']
['1940']
['1940']
['\\frac{13}{6}']
['\\frac{13}{6}']
['2']
['2']
['3']
['3']
['-120']
['-120']
['3']
['3']
['26000']
['26000']
['6']
['6']
['4343_6']
['4343_6']
['2k']
['2k']
['55']
['55']
['-2']
['-2']
['2']
['2']
['58500']
['58500']
['5']
['5']
['1']
['1']
['66']
['66']
['6r^2-4r-24']
['6r^2-4r-24']
['4495']
['4495']
['10080']
['10080']
['4']
['4']
['\\frac{1}{16}']
['\\frac{1}{16}']
['11(1+\\sqrt{5})']
['11(1+\\sqrt{5})']
['480']
['480']
['81']
['81']
['100']
['100']
['(-\\sqrt{3}\\sqrt{3})']
['(-\\sqrt{3}\\sqrt{3})']
['4']
['4']
['ellipse']
['ellipse']
['6']
['6']
['\\frac{7}{4}']
['\\frac{7}{4}']
['16\\sqrt{3}']
['16\\sqrt{3}']
['\\frac{1}{4}']
['\\frac{1}{4}']
['2']
['2']
['(1-16-443)']
['(1-16-443)']
['8']
['8']
['4']
['4']
['1']
['1']
['31']
['31']
['21']
['21']
['-41']
['-41']
['17']
['17']
['90']
['90']
['1+2i']
['1+2i']
['4']
['4']
['25']
['25']
['(8-2)']
['(8-2)']
['0']
['6']
['3']
['3']
['[invalid]']
['12']
['(09)\\cup(936)']
['(09)\\cup(936)']
['\\frac{1}{2}']
['\\frac{1}{2}']
['\\frac{20000}{\\pi}']
['\\frac{20000}{\\pi}']
['[-27]']
['[-27]']
['15x-80']
['15x-80']
['23']
['22']
['11']
['11']
['18']
['18']
['\\frac{11}{2}']
['\\frac{11}{2}']
['[invalid]']
['\\frac{\\sqrt{21}}{5}']
['12']
['12']
['0']
['0']
['\\sqrt{66}']
['\\sqrt{66}']
['\\frac{3}{4}']
['\\frac{3}{4}']
['-\\frac{3}{8}']
['-\\frac{3}{8}']
['4']
['4']
['2']
['2']
['23']
['23']
['[invalid]']
['navin']
['[invalid]']
['326.5']
['\\frac{14}{3}']
['\\frac{14}{3}']
2025-03-02:17:01:22,804 INFO     [lm_eval.loggers.evaluation_tracker:209] Saving results aggregated
2025-03-02:17:01:22,806 INFO     [lm_eval.loggers.evaluation_tracker:290] Saving per-sample results for: math-500
['\\frac{13}{4}']
['\\frac{13}{4}']
['1-12i']
['1-12i']
['3']
['3']
['3']
['3']
['60']
['60']
['0']
['0']
['9']
['9']
['\\begin{pmatrix}\\frac{1}{5}\\\\-\\frac{18}{5}\\end{pmatrix}']
['\\begin{pmatrix}\\frac{1}{5}\\\\-\\frac{18}{5}\\end{pmatrix}']
['2\\sqrt{5}']
['2\\sqrt{5}']
['6']
['6']
['60']
['60']
['406']
['406']
['5r^5']
['5r^5']
['10']
['10']
['9']
['9']
['\\frac{1}{8}']
['\\frac{1}{8}']
['-2']
['-2']
['2\\sqrt{5}']
['2\\sqrt{5}']
['\\begin{pmatrix}-7\\\\16\\\\5\\end{pmatrix}']
['\\begin{pmatrix}-7\\\\16\\\\5\\end{pmatrix}']
['\\begin{pmatrix}\\frac{16}{49}\\\\\\frac{48}{49}\\\\\\frac{24}{49}\\end{pmatrix}']
['\\begin{pmatrix}\\frac{16}{49}\\\\\\frac{48}{49}\\\\\\frac{24}{49}\\end{pmatrix}']
['27']
['27']
['[invalid]']
['\\{1\\pm\\sqrt{5}-2\\}']
['1440']
['1440']
['600']
['600']
['3r^2']
['3r^2']
['6\\sqrt{2}']
['6\\sqrt{2}']
['29']
['29']
['64']
['64']
['50']
['50']
['4.5']
['4.5']
['[\\frac{\\pi^2}{8}\\frac{5\\pi^2}{4}]']
['[\\frac{\\pi^2}{8}\\frac{5\\pi^2}{4}]']
['331']
['331']
['0.35625']
['0.35625']
['32']
['32']
['(-\\infty2)\\cup(3\\infty)']
['(-\\infty2)\\cup(3\\infty)']
['4']
['4']
['3']
['3']
['4']
['4']
['x^8+x^7+x^6+x^5+x^4+x^3+x^2+x+1']
['x^8+x^7+x^6+x^5+x^4+x^3+x^2+x+1']
['14']
['14']
['[invalid]']
['550']
['256']
['256']
['45']
['45']
['\\frac{1}{2}']
['\\frac{1}{2}']
['15']
['15']
['8']
['8']
['9']
['9']
['44']
['44']
['47']
['47']
['64']
['64']
['\\frac{639}{40}']
['\\frac{639}{40}']
['143']
['143']
['10']
['10']
['y=2x+3']
['y=2x+3']
['6']
['6']
['-2']
['-21']
['0']
['0']
['41']
['41']
['18.90']
['18.90']
['75']
['75']
['12']
['12']
['59']
['59']
['2']
['2']
['9']
['9']
['121']
['121']
['8\\pi']
['8\\pi']
['15']
['15']
['8']
['8']
['25']
['25']
['27648']
['27648']
['84']
['84']
['137\\frac{1}{2}']
['137\\frac{1}{2}']
['7']
['7']
['3']
['3']
['29']
['29']
['200']
['200']
['2']
['2']
['\\frac{2}{1005}']
['\\frac{2}{1005}']
['2']
['2']
['1']
['1']
['8n^2+4n+1']
['8n^2+4n+1']
['202']
['202']
['\\frac{8}{15}']
['\\frac{8}{15}']
['10']
['10']
['13']
['13']
['216']
['216']
['2']
['2']
['36']
['36']
['15']
['15']
['14']
['14']
['[invalid]']
['64']
['y=-2x']
['y=-2x']
['20']
['20']
['\\frac{1}{4}']
['\\frac{1}{4}']
['(212)\\cup(12102)']
['(212)\\cup(12102)']
['\\frac{5}{13}']
['\\frac{5}{13}']
['\\frac{7}{2}']
['\\frac{7}{2}']
['-1']
['-1']
['106']
['106']
openai-chat-completions (model=deepseek-reasoner,timeout=30,max_retries=10), gen_kwargs: (None), limit: 500.0, num_fewshot: 0, batch_size: 1
| Tasks  |Version|  Filter  |n-shot|  Metric   |   |Value|   |Stderr|
|--------|------:|----------|-----:|-----------|---|----:|---|-----:|
|math-500|      1|get-answer|     0|exact_match|↑  |0.944|±  |0.0103|
